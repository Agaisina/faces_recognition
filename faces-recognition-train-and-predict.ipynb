{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1345db47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T07:22:34.179162Z",
     "iopub.status.busy": "2025-07-22T07:22:34.178055Z",
     "iopub.status.idle": "2025-07-22T07:23:17.950258Z",
     "shell.execute_reply": "2025-07-22T07:23:17.948924Z",
     "shell.execute_reply.started": "2025-07-22T07:22:34.179126Z"
    },
    "papermill": {
     "duration": 0.014398,
     "end_time": "2025-07-28T09:58:22.066618",
     "exception": false,
     "start_time": "2025-07-28T09:58:22.052220",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e97c46",
   "metadata": {
    "papermill": {
     "duration": 0.013164,
     "end_time": "2025-07-28T09:58:22.093328",
     "exception": false,
     "start_time": "2025-07-28T09:58:22.080164",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Competition: https://codalab.lisn.upsaclay.fr/competitions/16970#learn_the_details-overview\n",
    "\n",
    "To promote and advance the use of synthetic data for face recognition, we organize the second edition of the Face Recognition Challenge in the Era of Synthetic Data (FRCSyn). This challenge intends to explore the application of synthetic data to the field of face recognition in order to find solutions to the current limitations in the technology, for example, in terms of privacy concerns associated with real data, bias in demographic groups (e.g., ethnicity and gender), and lack of performance in challenging conditions such as large age gaps between enrolment and testing, pose variations, occlusions, etc.\n",
    "\n",
    "This challenge intends to provide an in-depth analysis of the following research questions:\n",
    "\n",
    "What are the limits of face recognition technology trained only with synthetic data?\n",
    "Can the use of synthetic data be beneficial to reduce the current limitations in face recognition technology?\n",
    "This is a novel and very important research line nowadays due to the recent discontinuation of face recognition datasets due to privacy concerns. Furthermore, state-of-the-art face recognition technology has several limitations in terms of bias in demographic groups (e.g., ethnicity and gender), and lack of performance in challenging conditions such as large age gaps between enrolment and testing, pose variations, occlusions, etc.\n",
    "\n",
    "Here, we adress **Task 2: synthetic data for overall performance improvement** (e.g., according to age, pose, expression, occlusion, demographic groups, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eed3f950",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T09:58:22.121680Z",
     "iopub.status.busy": "2025-07-28T09:58:22.120983Z",
     "iopub.status.idle": "2025-07-28T10:00:09.829803Z",
     "shell.execute_reply": "2025-07-28T10:00:09.828667Z"
    },
    "papermill": {
     "duration": 107.726046,
     "end_time": "2025-07-28T10:00:09.832516",
     "exception": false,
     "start_time": "2025-07-28T09:58:22.106470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras<3.0.0\r\n",
      "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Collecting tensorflow<2.16\r\n",
      "  Downloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\r\n",
      "Collecting tf-models-official<2.16\r\n",
      "  Downloading tf_models_official-2.15.0-py2.py3-none-any.whl.metadata (1.4 kB)\r\n",
      "Collecting mediapipe-model-maker\r\n",
      "  Downloading mediapipe_model_maker-0.2.1.4-py3-none-any.whl.metadata (1.7 kB)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16) (1.4.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16) (24.3.25)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16) (0.5.4)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16) (0.2.0)\r\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16) (3.11.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16) (18.1.1)\r\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16) (0.3.2)\r\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16) (1.26.4)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16) (3.3.0)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16) (21.3)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16) (3.20.3)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16) (70.0.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16) (1.16.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16) (2.4.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16) (4.12.2)\r\n",
      "Collecting wrapt<1.15,>=1.11.0 (from tensorflow<2.16)\r\n",
      "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16) (0.37.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16) (1.62.2)\r\n",
      "Collecting tensorboard<2.16,>=2.15 (from tensorflow<2.16)\r\n",
      "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\r\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16) (2.15.0)\r\n",
      "Requirement already satisfied: Cython in /opt/conda/lib/python3.10/site-packages (from tf-models-official<2.16) (3.0.10)\r\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from tf-models-official<2.16) (10.3.0)\r\n",
      "Collecting gin-config (from tf-models-official<2.16)\r\n",
      "  Downloading gin_config-0.5.0-py3-none-any.whl.metadata (2.9 kB)\r\n",
      "Requirement already satisfied: google-api-python-client>=1.6.7 in /opt/conda/lib/python3.10/site-packages (from tf-models-official<2.16) (2.147.0)\r\n",
      "Requirement already satisfied: immutabledict in /opt/conda/lib/python3.10/site-packages (from tf-models-official<2.16) (4.2.0)\r\n",
      "Requirement already satisfied: kaggle>=1.3.9 in /opt/conda/lib/python3.10/site-packages (from tf-models-official<2.16) (1.6.17)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from tf-models-official<2.16) (3.7.5)\r\n",
      "Requirement already satisfied: oauth2client in /opt/conda/lib/python3.10/site-packages (from tf-models-official<2.16) (4.1.3)\r\n",
      "Requirement already satisfied: opencv-python-headless in /opt/conda/lib/python3.10/site-packages (from tf-models-official<2.16) (4.10.0.84)\r\n",
      "Requirement already satisfied: pandas>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from tf-models-official<2.16) (2.2.2)\r\n",
      "Requirement already satisfied: psutil>=5.4.3 in /opt/conda/lib/python3.10/site-packages (from tf-models-official<2.16) (5.9.3)\r\n",
      "Requirement already satisfied: py-cpuinfo>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from tf-models-official<2.16) (9.0.0)\r\n",
      "Collecting pycocotools (from tf-models-official<2.16)\r\n",
      "  Downloading pycocotools-2.0.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\r\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in /opt/conda/lib/python3.10/site-packages (from tf-models-official<2.16) (6.0.2)\r\n",
      "Collecting sacrebleu (from tf-models-official<2.16)\r\n",
      "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.10/site-packages (from tf-models-official<2.16) (1.14.1)\r\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from tf-models-official<2.16) (0.2.0)\r\n",
      "Collecting seqeval (from tf-models-official<2.16)\r\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: tensorflow-datasets in /opt/conda/lib/python3.10/site-packages (from tf-models-official<2.16) (4.9.6)\r\n",
      "Requirement already satisfied: tensorflow-hub>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from tf-models-official<2.16) (0.16.1)\r\n",
      "Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official<2.16)\r\n",
      "  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\r\n",
      "Collecting tensorflow-text~=2.15.0 (from tf-models-official<2.16)\r\n",
      "  Downloading tensorflow_text-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\r\n",
      "Collecting tf-slim>=1.1.0 (from tf-models-official<2.16)\r\n",
      "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl.metadata (1.6 kB)\r\n",
      "Collecting mediapipe>=0.10.0 (from mediapipe-model-maker)\r\n",
      "  Downloading mediapipe-0.10.21-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\r\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (from mediapipe-model-maker) (4.10.0.84)\r\n",
      "Collecting tensorflow-addons (from mediapipe-model-maker)\r\n",
      "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\r\n",
      "Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official<2.16)\r\n",
      "  Downloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl.metadata (914 bytes)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.16) (0.43.0)\r\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16) (0.21.0)\r\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16) (2.30.0)\r\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16) (0.2.0)\r\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16) (2.11.1)\r\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16) (3.0.1)\r\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /opt/conda/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official<2.16) (2024.8.30)\r\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official<2.16) (2.9.0.post0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official<2.16) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official<2.16) (4.66.4)\r\n",
      "Requirement already satisfied: python-slugify in /opt/conda/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official<2.16) (8.0.4)\r\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official<2.16) (1.26.18)\r\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official<2.16) (6.1.0)\r\n",
      "Requirement already satisfied: attrs>=19.1.0 in /opt/conda/lib/python3.10/site-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (23.2.0)\r\n",
      "Requirement already satisfied: jax in /opt/conda/lib/python3.10/site-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (0.4.26)\r\n",
      "Requirement already satisfied: jaxlib in /opt/conda/lib/python3.10/site-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (0.4.26.dev20240620)\r\n",
      "Requirement already satisfied: opencv-contrib-python in /opt/conda/lib/python3.10/site-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (4.10.0.84)\r\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow<2.16)\r\n",
      "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\r\n",
      "Collecting sounddevice>=0.4.4 (from mediapipe>=0.10.0->mediapipe-model-maker)\r\n",
      "  Downloading sounddevice-0.5.2-py3-none-any.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.22.0->tf-models-official<2.16) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.22.0->tf-models-official<2.16) (2024.1)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16) (1.2.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16) (3.6)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16) (3.0.4)\r\n",
      "Requirement already satisfied: tf-keras>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow-hub>=0.6.0->tf-models-official<2.16) (2.16.0)\r\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official<2.16) (0.1.8)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->tf-models-official<2.16) (1.2.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->tf-models-official<2.16) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->tf-models-official<2.16) (4.53.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->tf-models-official<2.16) (1.4.5)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->tf-models-official<2.16) (3.1.2)\r\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /opt/conda/lib/python3.10/site-packages (from oauth2client->tf-models-official<2.16) (0.6.0)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /opt/conda/lib/python3.10/site-packages (from oauth2client->tf-models-official<2.16) (0.4.0)\r\n",
      "Requirement already satisfied: rsa>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from oauth2client->tf-models-official<2.16) (4.9)\r\n",
      "Collecting portalocker (from sacrebleu->tf-models-official<2.16)\r\n",
      "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\r\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacrebleu->tf-models-official<2.16) (2024.5.15)\r\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu->tf-models-official<2.16) (0.9.0)\r\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu->tf-models-official<2.16) (0.4.6)\r\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu->tf-models-official<2.16) (5.3.0)\r\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.10/site-packages (from seqeval->tf-models-official<2.16) (1.2.2)\r\n",
      "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->mediapipe-model-maker)\r\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\r\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official<2.16) (8.1.7)\r\n",
      "Requirement already satisfied: promise in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official<2.16) (2.3)\r\n",
      "Requirement already satisfied: pyarrow in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official<2.16) (16.1.0)\r\n",
      "Requirement already satisfied: simple-parsing in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official<2.16) (0.1.5)\r\n",
      "Requirement already satisfied: tensorflow-metadata in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official<2.16) (0.14.0)\r\n",
      "Requirement already satisfied: toml in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official<2.16) (0.10.2)\r\n",
      "Requirement already satisfied: array-record>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official<2.16) (0.5.1)\r\n",
      "Requirement already satisfied: etils>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->tf-models-official<2.16) (1.7.0)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->tf-models-official<2.16) (2024.6.1)\r\n",
      "Requirement already satisfied: importlib_resources in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->tf-models-official<2.16) (6.4.0)\r\n",
      "Requirement already satisfied: zipp in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->tf-models-official<2.16) (3.19.2)\r\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official<2.16) (1.63.1)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.6.7->tf-models-official<2.16) (4.2.4)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16) (2.0.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle>=1.3.9->tf-models-official<2.16) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle>=1.3.9->tf-models-official<2.16) (3.7)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official<2.16) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official<2.16) (3.5.0)\r\n",
      "Requirement already satisfied: CFFI>=1.0 in /opt/conda/lib/python3.10/site-packages (from sounddevice>=0.4.4->mediapipe>=0.10.0->mediapipe-model-maker) (1.16.0)\r\n",
      "INFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\r\n",
      "Collecting tf-keras>=2.14.1 (from tensorflow-hub>=0.6.0->tf-models-official<2.16)\r\n",
      "  Downloading tf_keras-2.19.0-py3-none-any.whl.metadata (1.8 kB)\r\n",
      "  Downloading tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\r\n",
      "  Downloading tf_keras-2.17.0-py3-none-any.whl.metadata (1.6 kB)\r\n",
      "  Downloading tf_keras-2.15.1-py3-none-any.whl.metadata (1.7 kB)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16) (2.1.5)\r\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach->kaggle>=1.3.9->tf-models-official<2.16) (0.5.1)\r\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.10/site-packages (from python-slugify->kaggle>=1.3.9->tf-models-official<2.16) (1.3)\r\n",
      "Requirement already satisfied: docstring-parser~=0.15 in /opt/conda/lib/python3.10/site-packages (from simple-parsing->tensorflow-datasets->tf-models-official<2.16) (0.16)\r\n",
      "INFO: pip is looking at multiple versions of tensorflow-metadata to determine which version is compatible with other requirements. This could take a while.\r\n",
      "Collecting tensorflow-metadata (from tensorflow-datasets->tf-models-official<2.16)\r\n",
      "  Downloading tensorflow_metadata-1.17.2-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "  Downloading tensorflow_metadata-1.17.1-py3-none-any.whl.metadata (2.6 kB)\r\n",
      "  Downloading tensorflow_metadata-1.17.0-py3-none-any.whl.metadata (2.6 kB)\r\n",
      "  Downloading tensorflow_metadata-1.16.1-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "  Downloading tensorflow_metadata-1.16.0-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "  Downloading tensorflow_metadata-1.15.0-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "  Downloading tensorflow_metadata-1.14.0-py3-none-any.whl.metadata (2.1 kB)\r\n",
      "INFO: pip is still looking at multiple versions of tensorflow-metadata to determine which version is compatible with other requirements. This could take a while.\r\n",
      "  Downloading tensorflow_metadata-1.13.1-py3-none-any.whl.metadata (2.1 kB)\r\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe>=0.10.0->mediapipe-model-maker) (2.22)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16) (3.2.2)\r\n",
      "Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tf_models_official-2.15.0-py2.py3-none-any.whl (2.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading mediapipe_model_maker-0.2.1.4-py3-none-any.whl (133 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading mediapipe-0.10.21-cp310-cp310-manylinux_2_28_x86_64.whl (35.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m98.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl (241 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tensorflow_text-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading gin_config-0.5.0-py3-none-any.whl (61 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pycocotools-2.0.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (455 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m455.0/455.0 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading sounddevice-0.5.2-py3-none-any.whl (32 kB)\r\n",
      "Downloading tf_keras-2.15.1-py3-none-any.whl (1.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\r\n",
      "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\r\n",
      "Downloading tensorflow_metadata-1.13.1-py3-none-any.whl (28 kB)\r\n",
      "Building wheels for collected packages: seqeval\r\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=248f6ba2b34f3595c117df5c9a8808bb0a6be94eb27163ecbc89cdf553884ba9\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\r\n",
      "Successfully built seqeval\r\n",
      "Installing collected packages: gin-config, wrapt, typeguard, tf-slim, tensorflow-model-optimization, pycocotools, protobuf, portalocker, keras, tensorflow-addons, sounddevice, sacrebleu, tensorflow-metadata, seqeval, mediapipe, tensorboard, tensorflow, tf-keras, tensorflow-text, tf-models-official, mediapipe-model-maker\r\n",
      "  Attempting uninstall: wrapt\r\n",
      "    Found existing installation: wrapt 1.16.0\r\n",
      "    Uninstalling wrapt-1.16.0:\r\n",
      "      Successfully uninstalled wrapt-1.16.0\r\n",
      "  Attempting uninstall: typeguard\r\n",
      "    Found existing installation: typeguard 4.3.0\r\n",
      "    Uninstalling typeguard-4.3.0:\r\n",
      "      Successfully uninstalled typeguard-4.3.0\r\n",
      "  Attempting uninstall: protobuf\r\n",
      "    Found existing installation: protobuf 3.20.3\r\n",
      "    Uninstalling protobuf-3.20.3:\r\n",
      "      Successfully uninstalled protobuf-3.20.3\r\n",
      "  Attempting uninstall: keras\r\n",
      "    Found existing installation: keras 3.3.3\r\n",
      "    Uninstalling keras-3.3.3:\r\n",
      "      Successfully uninstalled keras-3.3.3\r\n",
      "  Attempting uninstall: tensorflow-metadata\r\n",
      "    Found existing installation: tensorflow-metadata 0.14.0\r\n",
      "    Uninstalling tensorflow-metadata-0.14.0:\r\n",
      "      Successfully uninstalled tensorflow-metadata-0.14.0\r\n",
      "  Attempting uninstall: tensorboard\r\n",
      "    Found existing installation: tensorboard 2.16.2\r\n",
      "    Uninstalling tensorboard-2.16.2:\r\n",
      "      Successfully uninstalled tensorboard-2.16.2\r\n",
      "  Attempting uninstall: tensorflow\r\n",
      "    Found existing installation: tensorflow 2.16.1\r\n",
      "    Uninstalling tensorflow-2.16.1:\r\n",
      "      Successfully uninstalled tensorflow-2.16.1\r\n",
      "  Attempting uninstall: tf-keras\r\n",
      "    Found existing installation: tf_keras 2.16.0\r\n",
      "    Uninstalling tf_keras-2.16.0:\r\n",
      "      Successfully uninstalled tf_keras-2.16.0\r\n",
      "  Attempting uninstall: tensorflow-text\r\n",
      "    Found existing installation: tensorflow-text 2.16.1\r\n",
      "    Uninstalling tensorflow-text-2.16.1:\r\n",
      "      Successfully uninstalled tensorflow-text-2.16.1\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "apache-beam 2.46.0 requires cloudpickle~=2.2.1, but you have cloudpickle 3.0.0 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires protobuf<4,>3.12.2, but you have protobuf 4.25.8 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\r\n",
      "google-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\r\n",
      "google-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\r\n",
      "google-cloud-bigquery 2.34.4 requires protobuf<4.0.0dev,>=3.12.0, but you have protobuf 4.25.8 which is incompatible.\r\n",
      "google-cloud-bigtable 1.7.3 requires protobuf<4.0.0dev, but you have protobuf 4.25.8 which is incompatible.\r\n",
      "google-cloud-vision 2.8.0 requires protobuf<4.0.0dev,>=3.19.0, but you have protobuf 4.25.8 which is incompatible.\r\n",
      "kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "kfp 2.5.0 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.8 which is incompatible.\r\n",
      "kfp-pipeline-spec 0.2.2 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.8 which is incompatible.\r\n",
      "tensorflow-decision-forests 1.9.1 requires tensorflow~=2.16.1, but you have tensorflow 2.15.1 which is incompatible.\r\n",
      "tensorflow-decision-forests 1.9.1 requires tf-keras~=2.16, but you have tf-keras 2.15.1 which is incompatible.\r\n",
      "tensorflow-serving-api 2.16.1 requires tensorflow<3,>=2.16.1, but you have tensorflow 2.15.1 which is incompatible.\r\n",
      "tensorflow-transform 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.8 which is incompatible.\r\n",
      "tensorflow-transform 0.14.0 requires tensorflow-metadata<0.15,>=0.14, but you have tensorflow-metadata 1.13.1 which is incompatible.\r\n",
      "ydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\r\n",
      "ydata-profiling 4.10.0 requires typeguard<5,>=3, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed gin-config-0.5.0 keras-2.15.0 mediapipe-0.10.21 mediapipe-model-maker-0.2.1.4 portalocker-3.2.0 protobuf-4.25.3 pycocotools-2.0.10 sacrebleu-2.5.1 seqeval-1.2.2 sounddevice-0.5.2 tensorboard-2.15.2 tensorflow-2.15.1 tensorflow-addons-0.23.0 tensorflow-metadata-1.13.1 tensorflow-model-optimization-0.7.5 tensorflow-text-2.15.0 tf-keras-2.15.1 tf-models-official-2.15.0 tf-slim-1.1.0 typeguard-2.13.3 wrapt-1.14.1\r\n",
      "Collecting numpy==1.23.5\r\n",
      "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\r\n",
      "Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: numpy\r\n",
      "  Attempting uninstall: numpy\r\n",
      "    Found existing installation: numpy 1.26.4\r\n",
      "    Uninstalling numpy-1.26.4:\r\n",
      "      Successfully uninstalled numpy-1.26.4\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cudf 24.8.3 requires cubinlinker, which is not installed.\r\n",
      "cudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "cudf 24.8.3 requires ptxcompiler, which is not installed.\r\n",
      "cuml 24.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "dask-cudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "ucxx 0.39.1 requires libucx>=1.15.0, which is not installed.\r\n",
      "albucore 0.0.17 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\r\n",
      "albumentations 1.4.17 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires cloudpickle~=2.2.1, but you have cloudpickle 3.0.0 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires protobuf<4,>3.12.2, but you have protobuf 4.25.3 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\r\n",
      "bayesian-optimization 1.5.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\r\n",
      "cesium 0.12.3 requires numpy<3.0,>=2.0, but you have numpy 1.23.5 which is incompatible.\r\n",
      "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\r\n",
      "cudf 24.8.3 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.0 which is incompatible.\r\n",
      "featuretools 1.31.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\r\n",
      "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.14.1 which is incompatible.\r\n",
      "ibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 16.1.0 which is incompatible.\r\n",
      "libpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "pyldavis 3.4.1 requires numpy>=1.24.2, but you have numpy 1.23.5 which is incompatible.\r\n",
      "rmm 24.8.2 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.0 which is incompatible.\r\n",
      "tensorflow-decision-forests 1.9.1 requires tensorflow~=2.16.1, but you have tensorflow 2.15.1 which is incompatible.\r\n",
      "tensorflow-decision-forests 1.9.1 requires tf-keras~=2.16, but you have tf-keras 2.15.1 which is incompatible.\r\n",
      "tensorflow-serving-api 2.16.1 requires tensorflow<3,>=2.16.1, but you have tensorflow 2.15.1 which is incompatible.\r\n",
      "tensorflow-transform 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.3 which is incompatible.\r\n",
      "tensorflow-transform 0.14.0 requires tensorflow-metadata<0.15,>=0.14, but you have tensorflow-metadata 1.13.1 which is incompatible.\r\n",
      "woodwork 0.31.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\r\n",
      "xarray 2024.9.0 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\r\n",
      "xarray 2024.9.0 requires packaging>=23.1, but you have packaging 21.3 which is incompatible.\r\n",
      "ydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\r\n",
      "ydata-profiling 4.10.0 requires typeguard<5,>=3, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed numpy-1.23.5\r\n",
      "Requirement already satisfied: tensorflow-addons in /opt/conda/lib/python3.10/site-packages (0.23.0)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow-addons) (21.3)\r\n",
      "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /opt/conda/lib/python3.10/site-packages (from tensorflow-addons) (2.13.3)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow-addons) (3.1.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install \"keras<3.0.0\" \"tensorflow<2.16\" \"tf-models-official<2.16\" mediapipe-model-maker\n",
    "!pip install numpy==1.23.5\n",
    "!pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c47ac9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:00:09.883814Z",
     "iopub.status.busy": "2025-07-28T10:00:09.883211Z",
     "iopub.status.idle": "2025-07-28T10:00:10.354091Z",
     "shell.execute_reply": "2025-07-28T10:00:10.353184Z"
    },
    "papermill": {
     "duration": 0.498647,
     "end_time": "2025-07-28T10:00:10.355997",
     "exception": false,
     "start_time": "2025-07-28T10:00:09.857350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/799906263.py:2: DeprecationWarning: Please import `QhullError` from the `scipy.spatial` namespace; the `scipy.spatial.qhull` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  from scipy.spatial.qhull import QhullError\n"
     ]
    }
   ],
   "source": [
    "# workaround compatible version\n",
    "from scipy.spatial.qhull import QhullError\n",
    "from scipy import spatial\n",
    "spatial.QhullError = QhullError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a9925ef",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-28T10:00:10.406839Z",
     "iopub.status.busy": "2025-07-28T10:00:10.406317Z",
     "iopub.status.idle": "2025-07-28T10:00:18.231407Z",
     "shell.execute_reply": "2025-07-28T10:00:18.230466Z"
    },
    "papermill": {
     "duration": 7.852749,
     "end_time": "2025-07-28T10:00:18.233518",
     "exception": false,
     "start_time": "2025-07-28T10:00:10.380769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-28 10:00:13.236327: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-28 10:00:13.236396: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-28 10:00:13.238134: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "from typing import Optional, Tuple, Callable\n",
    "\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from joblib import Parallel, delayed\n",
    "from PIL import Image\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Corrección de compatibilidad para np.bool\n",
    "np.bool = np.bool_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803c63d9",
   "metadata": {
    "papermill": {
     "duration": 0.023926,
     "end_time": "2025-07-28T10:00:18.282413",
     "exception": false,
     "start_time": "2025-07-28T10:00:18.258487",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 0. Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86b04d8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:00:18.332703Z",
     "iopub.status.busy": "2025-07-28T10:00:18.331628Z",
     "iopub.status.idle": "2025-07-28T10:00:18.428311Z",
     "shell.execute_reply": "2025-07-28T10:00:18.427459Z"
    },
    "papermill": {
     "duration": 0.123956,
     "end_time": "2025-07-28T10:00:18.430164",
     "exception": false,
     "start_time": "2025-07-28T10:00:18.306208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATH_SYNC: str = '/kaggle/input/faces-webface/faces_webface'\n",
    "MAX_SUBJECTS: int = len(os.listdir(PATH_SYNC))\n",
    "MAX_IMAGES_PER_SUBJECT: int = 50 # Determines the maximum number of unique subjects in the dataset by counting\n",
    "INPUT_SHAPE: Tuple[int, int, int] = (112, 112, 3) # width, height, and RGB channels\n",
    "PATH_MASKED_IDX_TRAIN_TEST: str = \"/kaggle/working/01_idx_train_test.pkl\" # precomputed training and testing indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b89422",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T08:26:16.890395Z",
     "iopub.status.busy": "2024-10-30T08:26:16.890019Z",
     "iopub.status.idle": "2024-10-30T08:26:16.895181Z",
     "shell.execute_reply": "2024-10-30T08:26:16.894313Z",
     "shell.execute_reply.started": "2024-10-30T08:26:16.890356Z"
    },
    "papermill": {
     "duration": 0.023976,
     "end_time": "2025-07-28T10:00:18.478867",
     "exception": false,
     "start_time": "2025-07-28T10:00:18.454891",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Create model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c347b86b",
   "metadata": {
    "papermill": {
     "duration": 0.024251,
     "end_time": "2025-07-28T10:00:18.527411",
     "exception": false,
     "start_time": "2025-07-28T10:00:18.503160",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## MobileFaceNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9cc2c6",
   "metadata": {
    "papermill": {
     "duration": 0.023821,
     "end_time": "2025-07-28T10:00:18.575330",
     "exception": false,
     "start_time": "2025-07-28T10:00:18.551509",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbe00cb",
   "metadata": {
    "papermill": {
     "duration": 0.023949,
     "end_time": "2025-07-28T10:00:18.623887",
     "exception": false,
     "start_time": "2025-07-28T10:00:18.599938",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "MobileFaceNet is a lightweight and efficient deep learning model designed specifically for face recognition tasks, particularly in resource-constrained environments such as mobile devices or edge devices. It aims to provide high accuracy while keeping the model size and computational requirements low.\n",
    "\n",
    "- **Architecture**:\n",
    "\n",
    "MobileFaceNet is based on the MobileNetV2 architecture, which utilizes depthwise separable convolutions and inverted residuals to reduce the number of parameters and computational cost.\n",
    "It consists of several layers of depthwise separable convolutions followed by global average pooling and fully connected layers\n",
    "\n",
    "- **Feature Extraction**:\n",
    "\n",
    "MobileFaceNet extracts discriminative features from face images using its convolutional layers.\n",
    "The depthwise separable convolutions help capture spatial information efficiently while reducing the number of parameters.\n",
    "Global average pooling is applied to aggregate spatial information and generate a compact feature representation.\n",
    "Embedding Generation:\n",
    "\n",
    "The output of the convolutional layers is passed through fully connected layers to generate a fixed-size embedding vector.\n",
    "This embedding vector encodes essential facial characteristics in a compact and discriminative manner.\n",
    "\n",
    "- **Loss Function**:\n",
    "\n",
    "MobileFaceNet typically uses a softmax-based loss function such as ArcFace or CosFace during training.\n",
    "These loss functions aim to maximize inter-class variations and minimize intra-class variations in the embedding space, leading to better face recognition performance.\n",
    "\n",
    "- **Model Optimization**:\n",
    "\n",
    "MobileFaceNet is designed to be efficient both in terms of model size and computational complexity.\n",
    "Techniques such as depthwise separable convolutions and model pruning are employed to reduce the number of parameters and inference latency\n",
    "\n",
    "- **Deployment**:\n",
    "\n",
    "Due to its lightweight nature, MobileFaceNet is suitable for deployment on mobile devices, edge devices, and other resource-constrained environments.\n",
    "It can be integrated into face recognition applications for tasks such as face authentication, access control, and identity verification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2988984",
   "metadata": {
    "papermill": {
     "duration": 0.064439,
     "end_time": "2025-07-28T10:00:18.712310",
     "exception": false,
     "start_time": "2025-07-28T10:00:18.647871",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Implementatition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aee316c",
   "metadata": {
    "papermill": {
     "duration": 0.024275,
     "end_time": "2025-07-28T10:00:18.760920",
     "exception": false,
     "start_time": "2025-07-28T10:00:18.736645",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Convolution Blocks** (*conv_block* and *separable_conv_block*): Defines reusable convolutional blocks with batch normalization and Swish activation. These blocks use standard and separable convolutions, which reduce model parameters and improve efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92ff82c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:00:18.811331Z",
     "iopub.status.busy": "2025-07-28T10:00:18.810989Z",
     "iopub.status.idle": "2025-07-28T10:00:18.816000Z",
     "shell.execute_reply": "2025-07-28T10:00:18.815155Z"
    },
    "papermill": {
     "duration": 0.032126,
     "end_time": "2025-07-28T10:00:18.817694",
     "exception": false,
     "start_time": "2025-07-28T10:00:18.785568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def conv_block(inputs, filters, kernel_size, strides):\n",
    "    x = tf.keras.layers.Conv2D(filters, kernel_size, padding=\"valid\", strides=strides,\n",
    "                               kernel_regularizer=tf.keras.regularizers.l2(1e-4)) (inputs)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=-1) (x)\n",
    "    x = tf.keras.layers.Activation(\"swish\") (x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "047be4ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:00:18.868415Z",
     "iopub.status.busy": "2025-07-28T10:00:18.868071Z",
     "iopub.status.idle": "2025-07-28T10:00:18.872877Z",
     "shell.execute_reply": "2025-07-28T10:00:18.872160Z"
    },
    "papermill": {
     "duration": 0.03212,
     "end_time": "2025-07-28T10:00:18.874393",
     "exception": false,
     "start_time": "2025-07-28T10:00:18.842273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def separable_conv_block(inputs, filters, kernel_size, strides):\n",
    "    x = tf.keras.layers.SeparableConv2D(filters=64, kernel_size=3, strides=(1, 1), padding=\"same\",\n",
    "                                        kernel_regularizer=tf.keras.regularizers.l2(1e-4)) (inputs)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=-1) (x)\n",
    "    x = tf.keras.layers.Activation(\"swish\") (x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0e6a0b",
   "metadata": {
    "papermill": {
     "duration": 0.023961,
     "end_time": "2025-07-28T10:00:18.923468",
     "exception": false,
     "start_time": "2025-07-28T10:00:18.899507",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Bottleneck Layer** (*bottleneck*): Implements the bottleneck structure from MobileNetV2 with an expansion-convolution-depthwise sequence. If r is set to True, it also applies a residual connection, enhancing feature reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3895eeb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:00:18.973204Z",
     "iopub.status.busy": "2025-07-28T10:00:18.972490Z",
     "iopub.status.idle": "2025-07-28T10:00:18.979824Z",
     "shell.execute_reply": "2025-07-28T10:00:18.979112Z"
    },
    "papermill": {
     "duration": 0.033773,
     "end_time": "2025-07-28T10:00:18.981330",
     "exception": false,
     "start_time": "2025-07-28T10:00:18.947557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bottleneck(inputs, filters, kernel, t, s, r=False):\n",
    "    tchannel = tf.keras.backend.int_shape(inputs)[-1] * t\n",
    "    x1 = conv_block(inputs, tchannel, (1, 1), (1, 1))\n",
    "    x1 = tf.keras.layers.DepthwiseConv2D(kernel_size=kernel, strides=s, padding=\"same\", depth_multiplier=1,\n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(1e-4)) (x1)\n",
    "    x1 = tf.keras.layers.BatchNormalization(axis=-1) (x1)\n",
    "    x1 = tf.keras.layers.Activation(\"swish\") (x1)\n",
    "    x2 = tf.keras.layers.Conv2D(filters, kernel_size=1, strides=1, padding=\"same\",\n",
    "                                kernel_regularizer=tf.keras.regularizers.l2(1e-4)) (x1)\n",
    "    x2 = tf.keras.layers.BatchNormalization(axis=-1) (x2)\n",
    "    if r:\n",
    "        x2 = tf.keras.layers.add([x2, inputs])\n",
    "    return x2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86638bb",
   "metadata": {
    "papermill": {
     "duration": 0.023843,
     "end_time": "2025-07-28T10:00:19.029981",
     "exception": false,
     "start_time": "2025-07-28T10:00:19.006138",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Inverted Residual Block** (*inverted_residual_block*): A loop of bottleneck layers with variable depth, strides, and residual connections for flexible feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc2545af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:00:19.080470Z",
     "iopub.status.busy": "2025-07-28T10:00:19.080172Z",
     "iopub.status.idle": "2025-07-28T10:00:19.084454Z",
     "shell.execute_reply": "2025-07-28T10:00:19.083817Z"
    },
    "papermill": {
     "duration": 0.032119,
     "end_time": "2025-07-28T10:00:19.086058",
     "exception": false,
     "start_time": "2025-07-28T10:00:19.053939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inverted_residual_block(inputs, filters, kernel, t, strides, n):\n",
    "    x = bottleneck(inputs, filters, kernel, t, strides)\n",
    "    for i in range(1, n):\n",
    "        x = bottleneck(x, filters, kernel, t, 1, True)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900866b4",
   "metadata": {
    "papermill": {
     "duration": 0.024221,
     "end_time": "2025-07-28T10:00:19.134333",
     "exception": false,
     "start_time": "2025-07-28T10:00:19.110112",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Linear Global Depthwise Convolution Block** (*linear_GD_conv_block*): Applies depthwise convolution with batch normalization, used later in the network to capture spatially pooled features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ec9eeed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:00:19.183626Z",
     "iopub.status.busy": "2025-07-28T10:00:19.183323Z",
     "iopub.status.idle": "2025-07-28T10:00:19.187618Z",
     "shell.execute_reply": "2025-07-28T10:00:19.186897Z"
    },
    "papermill": {
     "duration": 0.030895,
     "end_time": "2025-07-28T10:00:19.189241",
     "exception": false,
     "start_time": "2025-07-28T10:00:19.158346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def linear_GD_conv_block(inputs, kernel_size, strides):\n",
    "    \n",
    "    x = tf.keras.layers.DepthwiseConv2D(kernel_size=kernel_size, strides=strides, padding=\"valid\", depth_multiplier=1,\n",
    "                                        kernel_regularizer=tf.keras.regularizers.l2(1e-4)) (inputs)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=-1) (x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cd9067",
   "metadata": {
    "papermill": {
     "duration": 0.024007,
     "end_time": "2025-07-28T10:00:19.237528",
     "exception": false,
     "start_time": "2025-07-28T10:00:19.213521",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**MobileFaceNet Model Definition** (*mobile_face_net*): Combines all the defined layers into the final MobileFaceNet architecture. Layers stack according to a depthwise convolutional design, ending with a compact output of 128 channels, ideal for generating a compact face embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c1b991a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:00:19.286903Z",
     "iopub.status.busy": "2025-07-28T10:00:19.286572Z",
     "iopub.status.idle": "2025-07-28T10:00:19.291927Z",
     "shell.execute_reply": "2025-07-28T10:00:19.291247Z"
    },
    "papermill": {
     "duration": 0.032151,
     "end_time": "2025-07-28T10:00:19.293591",
     "exception": false,
     "start_time": "2025-07-28T10:00:19.261440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mobile_face_net(inputs):\n",
    "    x = conv_block(inputs, 64, 3, 2)\n",
    "    x = separable_conv_block(x, 64, 3, 1)\n",
    "    x = inverted_residual_block(x, 64, 3, t=2, strides=2, n=5)\n",
    "    x = inverted_residual_block(x, 128, 3, t=4, strides=2, n=1)\n",
    "    x = inverted_residual_block(x, 128, 3, t=2, strides=1, n=6)\n",
    "    x = inverted_residual_block(x, 128, 3, t=4, strides=2, n=1)\n",
    "    x = inverted_residual_block(x, 128, 3, t=2, strides=1, n=2)\n",
    "    x = conv_block(x, 512, 1, 1)\n",
    "    x = linear_GD_conv_block(x, 7, 1)\n",
    "    x = conv_block(x, 128, 1, 1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64331a08",
   "metadata": {
    "papermill": {
     "duration": 0.023941,
     "end_time": "2025-07-28T10:00:19.341613",
     "exception": false,
     "start_time": "2025-07-28T10:00:19.317672",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## ArcFace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d27c9fe",
   "metadata": {
    "papermill": {
     "duration": 0.023795,
     "end_time": "2025-07-28T10:00:19.389296",
     "exception": false,
     "start_time": "2025-07-28T10:00:19.365501",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The ArcFace model is a custom layer implemented in TensorFlow used in classification problems to enhance the separability of class features. It's based on the concept of the ArcFace loss function in feature space. The ArcFace model enhances class discrimination by adjusting the angles between features and class weight vectors, which can result in improved classification performance in multi-class classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f57a009",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:00:19.438394Z",
     "iopub.status.busy": "2025-07-28T10:00:19.438076Z",
     "iopub.status.idle": "2025-07-28T10:00:19.446452Z",
     "shell.execute_reply": "2025-07-28T10:00:19.445676Z"
    },
    "papermill": {
     "duration": 0.034804,
     "end_time": "2025-07-28T10:00:19.447947",
     "exception": false,
     "start_time": "2025-07-28T10:00:19.413143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ArcFace(tf.keras.layers.Layer):\n",
    "    def __init__(self, n_classes=10, s=64.0, m=0.5, regularizer=None, **kwargs):\n",
    "        super(ArcFace, self).__init__(**kwargs)\n",
    "        self.n_classes = n_classes\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.regularizer = tf.keras.regularizers.get(regularizer)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(ArcFace, self).build(input_shape[0])\n",
    "        self.W = self.add_weight(name='W',\n",
    "                                shape=(input_shape[0][-1], self.n_classes),\n",
    "                                initializer='glorot_uniform',\n",
    "                                trainable=True,\n",
    "                                regularizer=self.regularizer)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, y = inputs\n",
    "        c = tf.keras.backend.shape(x)[-1]\n",
    "        x = tf.nn.l2_normalize(x, axis=1)\n",
    "        W = tf.nn.l2_normalize(self.W, axis=0)\n",
    "        logits = x @ W\n",
    "        theta = tf.acos(tf.keras.backend.clip(logits, -1.0 \n",
    "                                              + tf.keras.backend.epsilon(), \n",
    "                                              1.0 - tf.keras.backend.epsilon()))\n",
    "        target_logits = tf.cos(theta + self.m)\n",
    "        logits = logits * (1 - y) + target_logits * y\n",
    "        logits *= self.s\n",
    "        out = tf.nn.softmax(logits)\n",
    "        return out\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.n_classes)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(ArcFace, self).get_config()\n",
    "        config.update({\n",
    "            'n_classes': self.n_classes,\n",
    "            's': self.s,\n",
    "            'm': self.m,\n",
    "            'regularizer': tf.keras.regularizers.serialize(self.regularizer)\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b1fb16",
   "metadata": {
    "papermill": {
     "duration": 0.024033,
     "end_time": "2025-07-28T10:00:19.496260",
     "exception": false,
     "start_time": "2025-07-28T10:00:19.472227",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f1fff3",
   "metadata": {
    "papermill": {
     "duration": 0.023901,
     "end_time": "2025-07-28T10:00:19.544402",
     "exception": false,
     "start_time": "2025-07-28T10:00:19.520501",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This section gathers all image file paths, splits them into training and testing sets, and saves these indices for consistency. With this dataset preparation complete, the model is now ready for training, allowing us to use the predefined training and testing splits to evaluate model performance reliably"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6eaf8291",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:00:19.593982Z",
     "iopub.status.busy": "2025-07-28T10:00:19.593678Z",
     "iopub.status.idle": "2025-07-28T10:01:29.193109Z",
     "shell.execute_reply": "2025-07-28T10:01:29.192386Z"
    },
    "papermill": {
     "duration": 69.626809,
     "end_time": "2025-07-28T10:01:29.195224",
     "exception": false,
     "start_time": "2025-07-28T10:00:19.568415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_images = np.asarray(glob.glob(PATH_SYNC +  \"*/**/*.png\"))\n",
    "\n",
    "idx_train, idx_test = train_test_split(range(file_images.shape[0]), test_size=0.3)\n",
    "\n",
    "with open(PATH_MASKED_IDX_TRAIN_TEST, \"wb\") as f:\n",
    "    pickle.dump([idx_train, idx_test], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db3b7778",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:01:29.245864Z",
     "iopub.status.busy": "2025-07-28T10:01:29.245509Z",
     "iopub.status.idle": "2025-07-28T10:01:29.277274Z",
     "shell.execute_reply": "2025-07-28T10:01:29.276622Z"
    },
    "papermill": {
     "duration": 0.058864,
     "end_time": "2025-07-28T10:01:29.279108",
     "exception": false,
     "start_time": "2025-07-28T10:01:29.220244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(PATH_MASKED_IDX_TRAIN_TEST, \"rb\") as f:\n",
    "    idx_train, idx_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dd2ae5",
   "metadata": {
    "papermill": {
     "duration": 0.024177,
     "end_time": "2025-07-28T10:01:29.328352",
     "exception": false,
     "start_time": "2025-07-28T10:01:29.304175",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The ArcFaceDataGenerator class is a custom data generator for TensorFlow, designed to load and preprocess face image data in batches for model training. Key functionalities include:\n",
    "\n",
    "- Initialization: Configures batch size, shuffling, and optional data augmentation. Augmentations include grayscale conversion, salt-and-pepper noise, solarization, Gaussian blur, gamma contrast, and color quantization.\n",
    "\n",
    "- Batch Loading: The __getitem__ method retrieves a batch of image files, loads each image, and converts it to an array format. It also assigns one-hot encoded labels based on the image path.\n",
    "\n",
    "- Data Augmentation: The __augment method applies augmentation if enabled, using a random combination of transformations for each batch to improve model generalization.\n",
    "\n",
    "- Epoch Handling: on_epoch_end shuffles the data indices at each epoch if shuffle is set to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73918071",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:01:29.378698Z",
     "iopub.status.busy": "2025-07-28T10:01:29.378339Z",
     "iopub.status.idle": "2025-07-28T10:01:29.391865Z",
     "shell.execute_reply": "2025-07-28T10:01:29.391151Z"
    },
    "papermill": {
     "duration": 0.040681,
     "end_time": "2025-07-28T10:01:29.393490",
     "exception": false,
     "start_time": "2025-07-28T10:01:29.352809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ArcFaceDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, \n",
    "                 file_images: np.ndarray,\n",
    "                 batch_size: Optional[int] = 8,\n",
    "                 shuffle: Optional[bool] = True,\n",
    "                 augment: Optional[bool] = True):\n",
    "        self.file_images = file_images\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(self.file_images.shape[0])\n",
    "        self.augment = augment\n",
    "        self.seq = iaa.SomeOf((1),\n",
    "                              [iaa.Identity(),\n",
    "                               iaa.Grayscale(alpha=1.),\n",
    "                               iaa.SaltAndPepper(p=0.1),\n",
    "                               iaa.Solarize(p=0.8),\n",
    "                               iaa.GaussianBlur(sigma=(0.25, 0.5)),\n",
    "                               iaa.GammaContrast(gamma=(0.5, 1.5)),\n",
    "                               iaa.UniformColorQuantizationToNBits(nb_bits=(3, 8)),\n",
    "                              ])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.indexes) / self.batch_size))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def __augment(self, images: np.ndarray):\n",
    "        images = list((images).astype(np.uint8))\n",
    "        images_aug = self.seq(images=images)\n",
    "        return np.asarray(images_aug, dtype=np.float32)\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        file_images = self.file_images[self.indexes[idx * self.batch_size : (idx + 1) * self.batch_size]]\n",
    "        X = []\n",
    "        y = np.zeros((len(file_images), MAX_SUBJECTS), dtype=np.float32)\n",
    "        for i, file_image in enumerate(file_images):\n",
    "            X_i = np.asarray(Image.open(file_image), dtype=np.float32)\n",
    "            X += [X_i]\n",
    "            y[i, int(file_image.split('/')[-2])] = 1.\n",
    "        X = np.stack(X)\n",
    "        if self.augment:\n",
    "            X = self.__augment(X)\n",
    "        \n",
    "        return [X / 255., y], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b19ee907",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:01:29.444321Z",
     "iopub.status.busy": "2025-07-28T10:01:29.443999Z",
     "iopub.status.idle": "2025-07-28T10:01:29.589356Z",
     "shell.execute_reply": "2025-07-28T10:01:29.588643Z"
    },
    "papermill": {
     "duration": 0.172995,
     "end_time": "2025-07-28T10:01:29.591405",
     "exception": false,
     "start_time": "2025-07-28T10:01:29.418410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_generator = ArcFaceDataGenerator(file_images=file_images[idx_train],\n",
    "                                            batch_size=64,\n",
    "                                            shuffle=True,\n",
    "                                            augment=True)\n",
    "test_data_generator = ArcFaceDataGenerator(file_images=file_images[idx_test],\n",
    "                                           batch_size=64,\n",
    "                                           shuffle=True,\n",
    "                                           augment=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea0ce35",
   "metadata": {
    "papermill": {
     "duration": 0.023802,
     "end_time": "2025-07-28T10:01:29.640339",
     "exception": false,
     "start_time": "2025-07-28T10:01:29.616537",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code snippet defines a part of a neural network architecture that consists of an input layer, a MobileFaceNet model, a flattening layer, and a fully connected layer. This architecture is often used in face recognition or feature extraction tasks, where MobileFaceNet is utilized to extract facial features, and the subsequent layers perform further processing or classification based on those features.\n",
    "\n",
    "- Input Layer: Accepts images with a shape defined by INPUT_SHAPE.\n",
    "- MobileFaceNet Backbone: Processes the input to extract compact facial features.\n",
    "- Flattening Layer: Converts the extracted features into a one-dimensional array.\n",
    "- Fully Connected Layer: Outputs a 512-dimensional feature vector, suitable for further classification or embedding in face recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64e62677",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:01:29.689539Z",
     "iopub.status.busy": "2025-07-28T10:01:29.689233Z",
     "iopub.status.idle": "2025-07-28T10:01:29.695409Z",
     "shell.execute_reply": "2025-07-28T10:01:29.694650Z"
    },
    "papermill": {
     "duration": 0.032838,
     "end_time": "2025-07-28T10:01:29.697074",
     "exception": false,
     "start_time": "2025-07-28T10:01:29.664236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ninputs = tf.keras.Input(shape=INPUT_SHAPE, dtype=tf.float32)\\nx = mobile_face_net(inputs)\\nx = tf.keras.layers.Flatten() (x)\\noutputs = tf.keras.layers.Dense(512, \\n                          kernel_initializer=\\'he_normal\\',\\n                          kernel_regularizer=tf.keras.regularizers.l2(1e-4)) (x)\\nbackbone_model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\\n#backbone_model.load_weights(\"./03_selfsupervised_backbone_model_v0.1.h5\")\\nbackbone_model.summary()\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "inputs = tf.keras.Input(shape=INPUT_SHAPE, dtype=tf.float32)\n",
    "x = mobile_face_net(inputs)\n",
    "x = tf.keras.layers.Flatten() (x)\n",
    "outputs = tf.keras.layers.Dense(512, \n",
    "                          kernel_initializer='he_normal',\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(1e-4)) (x)\n",
    "backbone_model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "#backbone_model.load_weights(\"./03_selfsupervised_backbone_model_v0.1.h5\")\n",
    "backbone_model.summary()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981797e6",
   "metadata": {
    "papermill": {
     "duration": 0.024089,
     "end_time": "2025-07-28T10:01:29.745967",
     "exception": false,
     "start_time": "2025-07-28T10:01:29.721878",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code loads a pretrained model from a saved file and is likely included to initialize the model with weights from a previous training session, which can save training time and improve performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d8e7338",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:01:29.797158Z",
     "iopub.status.busy": "2025-07-28T10:01:29.796253Z",
     "iopub.status.idle": "2025-07-28T10:01:32.301623Z",
     "shell.execute_reply": "2025-07-28T10:01:32.300655Z"
    },
    "papermill": {
     "duration": 2.533349,
     "end_time": "2025-07-28T10:01:32.303780",
     "exception": false,
     "start_time": "2025-07-28T10:01:29.770431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "backbone_model = tf.keras.models.load_model(\"/kaggle/input/arcface/tensorflow2/arcface_20epochs/1/04_model_arcface_v0.3_20.h5\")\n",
    "# backbone_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a739a292",
   "metadata": {
    "papermill": {
     "duration": 0.023881,
     "end_time": "2025-07-28T10:01:32.352623",
     "exception": false,
     "start_time": "2025-07-28T10:01:32.328742",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code sets up a neural network for face recognition using the ArcFace layer for enhanced classification.\n",
    "\n",
    "- **Inputs**:\n",
    "    - Image Input: The primary input layer inputs takes images with dimensions defined by INPUT_SHAPE.\n",
    "    - Label Input: An additional input, labels, takes a one-hot encoded label vector representing the subject identity, with a length of MAX_SUBJECTS (total number of classes)\n",
    "    \n",
    "- **Feature Extraction**:\n",
    "\n",
    "    - Backbone Model: The pretrained backbone_model processes the inputs to produce a feature embedding vector\n",
    "    \n",
    "- **ArcFace Layer**:\n",
    "\n",
    "    - The ArcFace layer is applied to the embedding and labels, enhancing inter-class separation with adjustable parameters s=16. (scaling factor) and m=0.3 (angular margin). This layer produces the final classification output, helping the model differentiate identities effectively.\n",
    "\n",
    "- **Model Assembly**:\n",
    "\n",
    "    - Model Definition: Combines both inputs (inputs and labels) to generate the final output with ArcFace-enhanced embeddings, creating a complete model ready for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "249ec8a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:01:32.402037Z",
     "iopub.status.busy": "2025-07-28T10:01:32.401707Z",
     "iopub.status.idle": "2025-07-28T10:01:32.407025Z",
     "shell.execute_reply": "2025-07-28T10:01:32.406180Z"
    },
    "papermill": {
     "duration": 0.032007,
     "end_time": "2025-07-28T10:01:32.408741",
     "exception": false,
     "start_time": "2025-07-28T10:01:32.376734",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'inputs = tf.keras.Input(shape=INPUT_SHAPE, dtype=tf.float32)\\nlabels = tf.keras.layers.Input(shape=(MAX_SUBJECTS, ), dtype=tf.float32)\\nx = backbone_model(inputs)\\noutputs = ArcFace(MAX_SUBJECTS, \\n                  regularizer=tf.keras.regularizers.l2(1e-4),\\n                  s=16., m=0.3) ([x, labels])\\nmodel = tf.keras.models.Model(inputs=[inputs, labels], \\n                              outputs=outputs)\\nmodel.summary()'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''inputs = tf.keras.Input(shape=INPUT_SHAPE, dtype=tf.float32)\n",
    "labels = tf.keras.layers.Input(shape=(MAX_SUBJECTS, ), dtype=tf.float32)\n",
    "x = backbone_model(inputs)\n",
    "outputs = ArcFace(MAX_SUBJECTS, \n",
    "                  regularizer=tf.keras.regularizers.l2(1e-4),\n",
    "                  s=16., m=0.3) ([x, labels])\n",
    "model = tf.keras.models.Model(inputs=[inputs, labels], \n",
    "                              outputs=outputs)\n",
    "model.summary()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af77186",
   "metadata": {
    "papermill": {
     "duration": 0.023975,
     "end_time": "2025-07-28T10:01:32.456972",
     "exception": false,
     "start_time": "2025-07-28T10:01:32.432997",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code compiles the model for training by configuring the optimizer, loss function, and evaluation metrics. It uses the Stochastic Gradient Descent (SGD) optimizer with a learning rate of 0.1 and a momentum of 0.5 to enhance convergence speed and stability. The loss function is set to categorical crossentropy, which is suitable for multi-class classification tasks, measuring the dissimilarity between predicted and true class probabilities. Additionally, accuracy is included as a metric to evaluate the model's performance during training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87f31530",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:01:32.507664Z",
     "iopub.status.busy": "2025-07-28T10:01:32.507316Z",
     "iopub.status.idle": "2025-07-28T10:01:32.512690Z",
     "shell.execute_reply": "2025-07-28T10:01:32.511862Z"
    },
    "papermill": {
     "duration": 0.03299,
     "end_time": "2025-07-28T10:01:32.514369",
     "exception": false,
     "start_time": "2025-07-28T10:01:32.481379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model.compile(optimizer=tf.keras.optimizers.SGD(lr=1e-1, momentum=0.5),\\n              loss=\"categorical_crossentropy\",\\n              metrics=[\"accuracy\"])'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''model.compile(optimizer=tf.keras.optimizers.SGD(lr=1e-1, momentum=0.5),\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef67a61",
   "metadata": {
    "papermill": {
     "duration": 0.024426,
     "end_time": "2025-07-28T10:01:32.566130",
     "exception": false,
     "start_time": "2025-07-28T10:01:32.541704",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code defines a CosineAnnealingScheduler class, a custom Keras callback designed to adjust the learning rate during training using a cosine annealing strategy\n",
    "\n",
    "The CosineAnnealingScheduler class inherits from tf.keras.callbacks.Callback and initializes parameters for learning rate scheduling, including hold (the number of epochs to maintain a constant learning rate), T_max (the number of epochs for a full cycle of learning rate adjustment), eta_max (the maximum learning rate), eta_min (the minimum learning rate), and verbose for logging. During each epoch, specifically in the on_epoch_begin method, the learning rate is updated according to a cosine function once the hold period is exceeded, smoothly varying the learning rate between eta_max and eta_min. This approach can enhance training efficiency and convergence. The on_epoch_end method also logs the current learning rate after each epoch, allowing for monitoring during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b471e8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:01:32.616259Z",
     "iopub.status.busy": "2025-07-28T10:01:32.615953Z",
     "iopub.status.idle": "2025-07-28T10:01:32.622667Z",
     "shell.execute_reply": "2025-07-28T10:01:32.621814Z"
    },
    "papermill": {
     "duration": 0.033883,
     "end_time": "2025-07-28T10:01:32.624316",
     "exception": false,
     "start_time": "2025-07-28T10:01:32.590433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CosineAnnealingScheduler(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, hold, T_max, eta_max, eta_min=0, verbose=0):\n",
    "        super(CosineAnnealingScheduler, self).__init__()\n",
    "        self.hold = hold\n",
    "        self.T_max = T_max\n",
    "        self.eta_max = eta_max\n",
    "        self.eta_min = eta_min\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        if not hasattr(self.model.optimizer, 'lr'):\n",
    "            raise ValueError('Optimizer must have a \"lr\" attribute.')\n",
    "        if epoch >= self.hold:\n",
    "            lr = self.eta_min + (self.eta_max - self.eta_min) * (1 + math.cos(math.pi * epoch / self.T_max)) / 2\n",
    "            tf.keras.backend.set_value(self.model.optimizer.lr, lr)\n",
    "            if self.verbose > 0:\n",
    "                print('\\nEpoch %05d: CosineAnnealingScheduler setting learning '\n",
    "                      'rate to %s.' % (epoch + 1, lr))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        logs['lr'] = tf.keras.backend.get_value(self.model.optimizer.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047b27ff",
   "metadata": {
    "papermill": {
     "duration": 0.024303,
     "end_time": "2025-07-28T10:01:32.673151",
     "exception": false,
     "start_time": "2025-07-28T10:01:32.648848",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code snippet sets up a list of callbacks for model training, enhancing the training process and allowing for better management of the training state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "549b5894",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:01:32.723229Z",
     "iopub.status.busy": "2025-07-28T10:01:32.722905Z",
     "iopub.status.idle": "2025-07-28T10:01:32.728545Z",
     "shell.execute_reply": "2025-07-28T10:01:32.727860Z"
    },
    "papermill": {
     "duration": 0.03264,
     "end_time": "2025-07-28T10:01:32.730128",
     "exception": false,
     "start_time": "2025-07-28T10:01:32.697488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"checkpoint_path = 'cp-{epoch:04d}.h5'\\n\\ncallbacks = [\\n    CosineAnnealingScheduler(hold=10, T_max=5, eta_max=1e-1, eta_min=1e-3, verbose=1),\\n    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\\n                                       save_weights_only=False,\\n                                       verbose=1)\\n]\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''checkpoint_path = 'cp-{epoch:04d}.h5'\n",
    "\n",
    "callbacks = [\n",
    "    CosineAnnealingScheduler(hold=10, T_max=5, eta_max=1e-1, eta_min=1e-3, verbose=1),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                       save_weights_only=False,\n",
    "                                       verbose=1)\n",
    "]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05228a41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:01:32.780511Z",
     "iopub.status.busy": "2025-07-28T10:01:32.780228Z",
     "iopub.status.idle": "2025-07-28T10:01:32.785308Z",
     "shell.execute_reply": "2025-07-28T10:01:32.784488Z"
    },
    "papermill": {
     "duration": 0.032128,
     "end_time": "2025-07-28T10:01:32.787101",
     "exception": false,
     "start_time": "2025-07-28T10:01:32.754973",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model.fit(train_data_generator,\\n          validation_data=test_data_generator,\\n          epochs=15,\\n          verbose=1,\\n          callbacks=callbacks)'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''model.fit(train_data_generator,\n",
    "          validation_data=test_data_generator,\n",
    "          epochs=15,\n",
    "          verbose=1,\n",
    "          callbacks=callbacks)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "731f342e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:01:32.836858Z",
     "iopub.status.busy": "2025-07-28T10:01:32.836577Z",
     "iopub.status.idle": "2025-07-28T10:01:32.841397Z",
     "shell.execute_reply": "2025-07-28T10:01:32.840665Z"
    },
    "papermill": {
     "duration": 0.031514,
     "end_time": "2025-07-28T10:01:32.842970",
     "exception": false,
     "start_time": "2025-07-28T10:01:32.811456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'backbone_model.save(\"04_model_arcface_v0.3_15_03.h5\")'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''backbone_model.save(\"04_model_arcface_v0.3_15_03.h5\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bca11774",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:01:32.893896Z",
     "iopub.status.busy": "2025-07-28T10:01:32.893264Z",
     "iopub.status.idle": "2025-07-28T10:01:32.898469Z",
     "shell.execute_reply": "2025-07-28T10:01:32.897646Z"
    },
    "papermill": {
     "duration": 0.0324,
     "end_time": "2025-07-28T10:01:32.900056",
     "exception": false,
     "start_time": "2025-07-28T10:01:32.867656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'backbone_model.save_weights(\"04_model_arcface_weights_v0.3_15_03.h5\")'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''backbone_model.save_weights(\"04_model_arcface_weights_v0.3_15_03.h5\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7543bad0",
   "metadata": {
    "papermill": {
     "duration": 0.024626,
     "end_time": "2025-07-28T10:01:32.949425",
     "exception": false,
     "start_time": "2025-07-28T10:01:32.924799",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Aproach 1: Locality Sensitive Hashing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f87ce6e",
   "metadata": {
    "papermill": {
     "duration": 0.024541,
     "end_time": "2025-07-28T10:01:32.998673",
     "exception": false,
     "start_time": "2025-07-28T10:01:32.974132",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This overall approach enables efficient neighbor search in high-dimensional spaces by leveraging the LSH technique, making it suitable for applications in face recognition and other similarity-based tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f05a06",
   "metadata": {
    "papermill": {
     "duration": 0.024789,
     "end_time": "2025-07-28T10:01:33.048448",
     "exception": false,
     "start_time": "2025-07-28T10:01:33.023659",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Create dataset: distance of closest neighborhood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd362771",
   "metadata": {
    "papermill": {
     "duration": 0.024675,
     "end_time": "2025-07-28T10:01:33.097680",
     "exception": false,
     "start_time": "2025-07-28T10:01:33.073005",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code snippet focuses on creating a dataset for finding the distance to the closest neighbors using Locality Sensitive Hashing (LSH) and cosine distance metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcc3db4",
   "metadata": {
    "papermill": {
     "duration": 0.024647,
     "end_time": "2025-07-28T10:01:33.146943",
     "exception": false,
     "start_time": "2025-07-28T10:01:33.122296",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The code begins by loading a preprocessed dataset from a pickle file named \"05_embeds.pkl\". This dataset likely contains embeddings or features of the data points.\n",
    "It also loads the train and test indices from a previously saved file, \"PATH_MASKED_IDX_TRAIN_TEST\", which will be used for training and testing splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d835e319",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:01:33.198102Z",
     "iopub.status.busy": "2025-07-28T10:01:33.197757Z",
     "iopub.status.idle": "2025-07-28T10:01:33.203304Z",
     "shell.execute_reply": "2025-07-28T10:01:33.202444Z"
    },
    "papermill": {
     "duration": 0.033278,
     "end_time": "2025-07-28T10:01:33.205019",
     "exception": false,
     "start_time": "2025-07-28T10:01:33.171741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'with open(\"/kaggle/input/frcsyn-models/05_embeds.pkl\", \"rb\") as f:\\n    data = pickle.load(f)'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''with open(\"/kaggle/input/frcsyn-models/05_embeds.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6415804d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:01:33.255548Z",
     "iopub.status.busy": "2025-07-28T10:01:33.255277Z",
     "iopub.status.idle": "2025-07-28T10:01:33.260219Z",
     "shell.execute_reply": "2025-07-28T10:01:33.259478Z"
    },
    "papermill": {
     "duration": 0.031679,
     "end_time": "2025-07-28T10:01:33.261654",
     "exception": false,
     "start_time": "2025-07-28T10:01:33.229975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'with open(PATH_MASKED_IDX_TRAIN_TEST, \"rb\") as f:\\n    idx_train, idx_test = pickle.load(f)'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''with open(PATH_MASKED_IDX_TRAIN_TEST, \"rb\") as f:\n",
    "    idx_train, idx_test = pickle.load(f)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf0bb61",
   "metadata": {
    "papermill": {
     "duration": 0.02456,
     "end_time": "2025-07-28T10:01:33.312473",
     "exception": false,
     "start_time": "2025-07-28T10:01:33.287913",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Generating Random Vectors**:\n",
    "\n",
    "The generate_random_vectors function creates random vectors that are used in the LSH algorithm to hash input vectors into binary codes, aiding in efficient similarity searches.\n",
    "\n",
    "**Training the LSH Model**:\n",
    "\n",
    "The train_lsh function trains a Locality Sensitive Hashing model using the TF-IDF vectors of the data. It generates random vectors, computes binary indices for the TF-IDF data, and organizes these indices into a hash table. This table maps binary codes to the original data indices for quick access.\n",
    "\n",
    "**Searching Nearby Bins**:\n",
    "\n",
    "The search_nearby_bins function allows searching for nearby bins in the LSH hash table based on a query vector. It generates variations of the query's binary representation by flipping a specified number of bits (search_radius) and retrieves candidate indices from the hash table.\n",
    "\n",
    "**Retrieving Nearest Neighbors**:\n",
    "\n",
    "The get_nearest_neighbors function finds the nearest neighbors of a query vector. It uses the trained LSH model to identify candidate indices and calculates the cosine distances between the query vector and the candidates. The results are returned in a DataFrame, sorted by distance, containing the indices and their corresponding distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f65587b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:01:33.363807Z",
     "iopub.status.busy": "2025-07-28T10:01:33.363460Z",
     "iopub.status.idle": "2025-07-28T10:01:33.373186Z",
     "shell.execute_reply": "2025-07-28T10:01:33.372461Z"
    },
    "papermill": {
     "duration": 0.037228,
     "end_time": "2025-07-28T10:01:33.374658",
     "exception": false,
     "start_time": "2025-07-28T10:01:33.337430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This function generates random vectors used in Locality Sensitive Hashing (LSH)\n",
    "\n",
    "def generate_random_vectors(dim, n_vectors):\n",
    "    return np.random.randn(dim, n_vectors)\n",
    "\n",
    "# This function trains a Locality Sensitive Hashing (LSH) model using the TF-IDF vectors of the data\n",
    "def train_lsh(X_tfidf, n_vectors, seed=None):    \n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    dim = X_tfidf.shape[1]\n",
    "    random_vectors = generate_random_vectors(dim, n_vectors)\n",
    "    bin_indices_bits = X_tfidf.dot(random_vectors) >= 0\n",
    "    powers_of_two = 1 << np.arange(n_vectors - 1, -1, step=-1)\n",
    "    bin_indices = bin_indices_bits.dot(powers_of_two)\n",
    "    table = defaultdict(list)\n",
    "    for idx, bin_index in enumerate(bin_indices):\n",
    "        table[bin_index].append(idx)\n",
    "    model = {'table': table,\n",
    "             'random_vectors': random_vectors,\n",
    "             'bin_indices': bin_indices,\n",
    "             'bin_indices_bits': bin_indices_bits}\n",
    "    return model\n",
    "\n",
    "# This function searches nearby bins in the LSH hash table based on the query vector\n",
    "def search_nearby_bins(query_bin_bits, table, search_radius=3, candidate_set=None):\n",
    "    if candidate_set is None:\n",
    "        candidate_set = set()\n",
    "    n_vectors = query_bin_bits.shape[0]\n",
    "    powers_of_two = 1 << np.arange(n_vectors - 1, -1, step=-1)\n",
    "    for different_bits in combinations(range(n_vectors), search_radius):\n",
    "        index = list(different_bits)\n",
    "        alternate_bits = query_bin_bits.copy()\n",
    "        alternate_bits[index] = np.logical_not(alternate_bits[index])\n",
    "        nearby_bin = alternate_bits.dot(powers_of_two)\n",
    "        if nearby_bin in table:\n",
    "            candidate_set.update(table[nearby_bin])\n",
    "    return candidate_set\n",
    "\n",
    "# This function retrieves the nearest neighbors of a query vector using the trained LSH model\n",
    "def get_nearest_neighbors(X_tfidf, query_vector, model, max_search_radius=3):\n",
    "    table = model['table']\n",
    "    random_vectors = model['random_vectors']\n",
    "    bin_index_bits = np.ravel(query_vector.dot(random_vectors) >= 0)\n",
    "    candidate_set = set()\n",
    "    for search_radius in range(max_search_radius + 1):\n",
    "        candidate_set = search_nearby_bins(bin_index_bits, table, search_radius, candidate_set)\n",
    "    candidate_list = list(candidate_set)\n",
    "    candidates = X_tfidf[candidate_list]\n",
    "    distance = pairwise_distances(candidates, query_vector, metric='cosine').flatten()\n",
    "    distance_col = 'distance'\n",
    "    nearest_neighbors = pd.DataFrame({\n",
    "        'id': candidate_list, distance_col: distance\n",
    "    }).sort_values(distance_col).reset_index(drop=True)\n",
    "    return nearest_neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb2dc1f",
   "metadata": {
    "papermill": {
     "duration": 0.024536,
     "end_time": "2025-07-28T10:01:33.423960",
     "exception": false,
     "start_time": "2025-07-28T10:01:33.399424",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code snippet demonstrates the process of using the trained Locality Sensitive Hashing (LSH) model to find the nearest neighbors of a specific embedding from the dataset, along with an implementation of the K-Nearest Neighbors (KNN) classifier for further classification tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16064f1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:01:33.474481Z",
     "iopub.status.busy": "2025-07-28T10:01:33.474188Z",
     "iopub.status.idle": "2025-07-28T10:01:33.477999Z",
     "shell.execute_reply": "2025-07-28T10:01:33.477311Z"
    },
    "papermill": {
     "duration": 0.030793,
     "end_time": "2025-07-28T10:01:33.479493",
     "exception": false,
     "start_time": "2025-07-28T10:01:33.448700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = train_lsh(np.stack(data[\"embeds\"].values), 16, seed=143)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d57de42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:01:33.530369Z",
     "iopub.status.busy": "2025-07-28T10:01:33.530052Z",
     "iopub.status.idle": "2025-07-28T10:01:33.533934Z",
     "shell.execute_reply": "2025-07-28T10:01:33.533260Z"
    },
    "papermill": {
     "duration": 0.030966,
     "end_time": "2025-07-28T10:01:33.535465",
     "exception": false,
     "start_time": "2025-07-28T10:01:33.504499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b467071",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:01:33.586363Z",
     "iopub.status.busy": "2025-07-28T10:01:33.586064Z",
     "iopub.status.idle": "2025-07-28T10:01:33.591457Z",
     "shell.execute_reply": "2025-07-28T10:01:33.590725Z"
    },
    "papermill": {
     "duration": 0.032408,
     "end_time": "2025-07-28T10:01:33.593085",
     "exception": false,
     "start_time": "2025-07-28T10:01:33.560677",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'item_id = idx_test[0]\\nquery_vector = data[\"embeds\"].values[item_id].reshape(1, -1)\\nnearest_neighbors = get_nearest_neighbors(np.stack(data[\"embeds\"].values), \\n                                          query_vector, \\n                                          model, \\n                                          max_search_radius=3)\\nprint(\\'query: \\', data[[\"user\", \"image\"]].values[item_id])\\npd.DataFrame([(data[\"user\"].values[nearest_neighbors[\"id\"].values[i]],\\n               data[\"image\"].values[nearest_neighbors[\"id\"].values[i]],\\n               nearest_neighbors[\"distance\"].values[i]) for i in range(100)],\\n             columns=[\"user\", \"image\", \"distance\"])'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''item_id = idx_test[0]\n",
    "query_vector = data[\"embeds\"].values[item_id].reshape(1, -1)\n",
    "nearest_neighbors = get_nearest_neighbors(np.stack(data[\"embeds\"].values), \n",
    "                                          query_vector, \n",
    "                                          model, \n",
    "                                          max_search_radius=3)\n",
    "print('query: ', data[[\"user\", \"image\"]].values[item_id])\n",
    "pd.DataFrame([(data[\"user\"].values[nearest_neighbors[\"id\"].values[i]],\n",
    "               data[\"image\"].values[nearest_neighbors[\"id\"].values[i]],\n",
    "               nearest_neighbors[\"distance\"].values[i]) for i in range(100)],\n",
    "             columns=[\"user\", \"image\", \"distance\"])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3d319e55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:01:33.644247Z",
     "iopub.status.busy": "2025-07-28T10:01:33.643991Z",
     "iopub.status.idle": "2025-07-28T10:01:33.649007Z",
     "shell.execute_reply": "2025-07-28T10:01:33.648322Z"
    },
    "papermill": {
     "duration": 0.032005,
     "end_time": "2025-07-28T10:01:33.650512",
     "exception": false,
     "start_time": "2025-07-28T10:01:33.618507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nneigh = KNeighborsClassifier(n_neighbors=10,\\n                             metric=\"cosine\",\\n                             n_jobs=-1)\\nneigh.fit(np.stack(data[\"embeds\"].values[idx_train]), data[\"user\"].values[idx_train])\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "neigh = KNeighborsClassifier(n_neighbors=10,\n",
    "                             metric=\"cosine\",\n",
    "                             n_jobs=-1)\n",
    "neigh.fit(np.stack(data[\"embeds\"].values[idx_train]), data[\"user\"].values[idx_train])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9aaa752",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:01:33.701994Z",
     "iopub.status.busy": "2025-07-28T10:01:33.701744Z",
     "iopub.status.idle": "2025-07-28T10:01:33.706877Z",
     "shell.execute_reply": "2025-07-28T10:01:33.706123Z"
    },
    "papermill": {
     "duration": 0.032693,
     "end_time": "2025-07-28T10:01:33.708368",
     "exception": false,
     "start_time": "2025-07-28T10:01:33.675675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y_pred = neigh.predict(np.stack(data[\"embeds\"].values[idx_test]))'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''y_pred = neigh.predict(np.stack(data[\"embeds\"].values[idx_test]))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0343c42e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:01:33.767516Z",
     "iopub.status.busy": "2025-07-28T10:01:33.766763Z",
     "iopub.status.idle": "2025-07-28T10:01:33.772091Z",
     "shell.execute_reply": "2025-07-28T10:01:33.771274Z"
    },
    "papermill": {
     "duration": 0.039851,
     "end_time": "2025-07-28T10:01:33.773640",
     "exception": false,
     "start_time": "2025-07-28T10:01:33.733789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'accuracy_score(data[\"user\"].values[idx_test], y_pred)\\n# 0.9586143790849673'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''accuracy_score(data[\"user\"].values[idx_test], y_pred)\n",
    "# 0.9586143790849673'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19420338",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:01:33.826331Z",
     "iopub.status.busy": "2025-07-28T10:01:33.825779Z",
     "iopub.status.idle": "2025-07-28T10:01:33.831376Z",
     "shell.execute_reply": "2025-07-28T10:01:33.830616Z"
    },
    "papermill": {
     "duration": 0.033726,
     "end_time": "2025-07-28T10:01:33.833080",
     "exception": false,
     "start_time": "2025-07-28T10:01:33.799354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef search(query):\\n    query_user, query_image, query_vector = query\\n    query_vector = query_vector.reshape(1, -1)\\n    nearest_neighbors = get_nearest_neighbors(np.stack(data[\"embeds\"].values), \\n                                              query_vector, \\n                                              model, \\n                                              max_search_radius=3)\\n    result = pd.DataFrame([(data[\"user\"].values[nearest_neighbors[\"id\"].values[j]],\\n                            data[\"image\"].values[nearest_neighbors[\"id\"].values[j]],\\n                            nearest_neighbors[\"distance\"].values[j]) for j in range(1, min(100, len(nearest_neighbors)))],\\n                          columns=[\"user\", \"image\", \"distance\"])\\n    result[\"query_user\"] = query_user\\n    result[\"query_image\"] = query_image\\n    return result\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def search(query):\n",
    "    query_user, query_image, query_vector = query\n",
    "    query_vector = query_vector.reshape(1, -1)\n",
    "    nearest_neighbors = get_nearest_neighbors(np.stack(data[\"embeds\"].values), \n",
    "                                              query_vector, \n",
    "                                              model, \n",
    "                                              max_search_radius=3)\n",
    "    result = pd.DataFrame([(data[\"user\"].values[nearest_neighbors[\"id\"].values[j]],\n",
    "                            data[\"image\"].values[nearest_neighbors[\"id\"].values[j]],\n",
    "                            nearest_neighbors[\"distance\"].values[j]) for j in range(1, min(100, len(nearest_neighbors)))],\n",
    "                          columns=[\"user\", \"image\", \"distance\"])\n",
    "    result[\"query_user\"] = query_user\n",
    "    result[\"query_image\"] = query_image\n",
    "    return result\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5bdeeaa7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:01:33.891507Z",
     "iopub.status.busy": "2025-07-28T10:01:33.891113Z",
     "iopub.status.idle": "2025-07-28T10:01:33.897062Z",
     "shell.execute_reply": "2025-07-28T10:01:33.896049Z"
    },
    "papermill": {
     "duration": 0.040271,
     "end_time": "2025-07-28T10:01:33.899011",
     "exception": false,
     "start_time": "2025-07-28T10:01:33.858740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nresults_train = pd.concat([search(data.values[idx]) \\n                           for idx in np.random.choice(idx_train, size=10_000, replace=False)], \\n                           ignore_index=True)\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "results_train = pd.concat([search(data.values[idx]) \n",
    "                           for idx in np.random.choice(idx_train, size=10_000, replace=False)], \n",
    "                           ignore_index=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc555ee0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:01:33.968304Z",
     "iopub.status.busy": "2025-07-28T10:01:33.967452Z",
     "iopub.status.idle": "2025-07-28T10:01:33.972927Z",
     "shell.execute_reply": "2025-07-28T10:01:33.972092Z"
    },
    "papermill": {
     "duration": 0.038749,
     "end_time": "2025-07-28T10:01:33.974565",
     "exception": false,
     "start_time": "2025-07-28T10:01:33.935816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nresults_test = pd.concat([search(data.values[idx]) \\n                          for idx in np.random.choice(idx_test, size=10_000, replace=False)], \\n                          ignore_index=True)\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "results_test = pd.concat([search(data.values[idx]) \n",
    "                          for idx in np.random.choice(idx_test, size=10_000, replace=False)], \n",
    "                          ignore_index=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b151cdbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:01:34.026972Z",
     "iopub.status.busy": "2025-07-28T10:01:34.026715Z",
     "iopub.status.idle": "2025-07-28T10:01:34.031415Z",
     "shell.execute_reply": "2025-07-28T10:01:34.030642Z"
    },
    "papermill": {
     "duration": 0.032731,
     "end_time": "2025-07-28T10:01:34.033040",
     "exception": false,
     "start_time": "2025-07-28T10:01:34.000309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'with open(\"06_datasets_v0.1.pkl\", \"wb\") as f:\\n    pickle.dump([results_train, results_test], f)'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''with open(\"06_datasets_v0.1.pkl\", \"wb\") as f:\n",
    "    pickle.dump([results_train, results_test], f)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0de328d",
   "metadata": {
    "papermill": {
     "duration": 0.025444,
     "end_time": "2025-07-28T10:01:34.084237",
     "exception": false,
     "start_time": "2025-07-28T10:01:34.058793",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Aproach 2: Identification model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6223f92c",
   "metadata": {
    "papermill": {
     "duration": 0.025336,
     "end_time": "2025-07-28T10:01:34.134763",
     "exception": false,
     "start_time": "2025-07-28T10:01:34.109427",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Siamese neural network architecture, where two identical backbone models share weights to extract features from two input images. These features are then concatenated and passed through dense layers to make a binary classification decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "978aabfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:01:34.187809Z",
     "iopub.status.busy": "2025-07-28T10:01:34.187056Z",
     "iopub.status.idle": "2025-07-28T10:01:34.192693Z",
     "shell.execute_reply": "2025-07-28T10:01:34.191923Z"
    },
    "papermill": {
     "duration": 0.034065,
     "end_time": "2025-07-28T10:01:34.194328",
     "exception": false,
     "start_time": "2025-07-28T10:01:34.160263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'with open(\"/kaggle/input/06-datasets-real/06_datasets_v0.1.pkl\", \"rb\") as f:\\n    results_train, results_test = pickle.load(f)'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''with open(\"/kaggle/input/06-datasets-real/06_datasets_v0.1.pkl\", \"rb\") as f:\n",
    "    results_train, results_test = pickle.load(f)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544508a8",
   "metadata": {
    "papermill": {
     "duration": 0.025228,
     "end_time": "2025-07-28T10:01:34.247437",
     "exception": false,
     "start_time": "2025-07-28T10:01:34.222209",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This generator class is designed to generate batches of data for training a model for identification tasks, such as determining whether two images belong to the same user. It incorporates options for shuffling data, applying augmentation techniques, and handling data loading in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "49ed0c10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:01:34.301436Z",
     "iopub.status.busy": "2025-07-28T10:01:34.301119Z",
     "iopub.status.idle": "2025-07-28T10:01:34.311175Z",
     "shell.execute_reply": "2025-07-28T10:01:34.310475Z"
    },
    "papermill": {
     "duration": 0.038207,
     "end_time": "2025-07-28T10:01:34.312665",
     "exception": false,
     "start_time": "2025-07-28T10:01:34.274458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class IdentificationDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, \n",
    "                 comparison: np.ndarray,\n",
    "                 batch_size: Optional[int] = 8,\n",
    "                 shuffle: Optional[bool] = True,\n",
    "                 augment: Optional[bool] = True):\n",
    "        self.comparison = comparison\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(self.comparison.shape[0])\n",
    "        self.augment = augment\n",
    "        self.seq = iaa.SomeOf((1),\n",
    "                              [iaa.Identity(),\n",
    "                               iaa.Grayscale(alpha=1.),\n",
    "                               iaa.SaltAndPepper(p=0.1),\n",
    "                               iaa.Solarize(p=0.8),\n",
    "                               iaa.GaussianBlur(sigma=(0.25, 0.5)),\n",
    "                               iaa.GammaContrast(gamma=(0.5, 1.5)),\n",
    "                               iaa.UniformColorQuantizationToNBits(nb_bits=(3, 8))\n",
    "                              ])\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.indexes) / self.batch_size))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def __augment(self, images: np.ndarray):\n",
    "        images = list((images).astype(np.uint8))\n",
    "        images_aug = self.seq(images=images)\n",
    "        return np.asarray(images_aug, dtype=np.float32)\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        comparison = self.comparison[self.indexes[idx * self.batch_size : (idx + 1) * self.batch_size]]\n",
    "        X_1 = []\n",
    "        X_2 = []\n",
    "        y = np.zeros(len(comparison), dtype=np.float32)\n",
    "        for i, [user_1, file_1, _, user_2, file_2] in enumerate(comparison):\n",
    "            X_1 += [np.asarray(Image.open(PATH_SYNC + \"/\" + user_1 + \"/\" + file_1), dtype=np.float32)]\n",
    "            X_2 += [np.asarray(Image.open(PATH_SYNC + \"/\" + user_2 + \"/\" + file_2), dtype=np.float32)]\n",
    "            y[i] = int(user_1 == user_2)\n",
    "        X_1 = np.stack(X_1)\n",
    "        X_2 = np.stack(X_2)\n",
    "        if self.augment:\n",
    "            X_1 = self.__augment(X_1)\n",
    "            X_2 = self.__augment(X_2)\n",
    "        \n",
    "        return [X_1 / 255., X_2 / 255.], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2f233e88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:01:34.365266Z",
     "iopub.status.busy": "2025-07-28T10:01:34.364957Z",
     "iopub.status.idle": "2025-07-28T10:01:34.370352Z",
     "shell.execute_reply": "2025-07-28T10:01:34.369598Z"
    },
    "papermill": {
     "duration": 0.033624,
     "end_time": "2025-07-28T10:01:34.371860",
     "exception": false,
     "start_time": "2025-07-28T10:01:34.338236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_data_generator = IdentificationDataGenerator(comparison=results_train,\\n                                                   batch_size=32,\\n                                                   shuffle=True,\\n                                                   augment=True)\\ntest_data_generator = IdentificationDataGenerator(comparison=results_test,\\n                                                  batch_size=32,\\n                                                  shuffle=True,\\n                                                  augment=False)'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''train_data_generator = IdentificationDataGenerator(comparison=results_train,\n",
    "                                                   batch_size=32,\n",
    "                                                   shuffle=True,\n",
    "                                                   augment=True)\n",
    "test_data_generator = IdentificationDataGenerator(comparison=results_test,\n",
    "                                                  batch_size=32,\n",
    "                                                  shuffle=True,\n",
    "                                                  augment=False)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "26faa10d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:01:34.423734Z",
     "iopub.status.busy": "2025-07-28T10:01:34.423456Z",
     "iopub.status.idle": "2025-07-28T10:01:34.428403Z",
     "shell.execute_reply": "2025-07-28T10:01:34.427578Z"
    },
    "papermill": {
     "duration": 0.032786,
     "end_time": "2025-07-28T10:01:34.429970",
     "exception": false,
     "start_time": "2025-07-28T10:01:34.397184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'backbone_model = tf.keras.models.load_model(\"/kaggle/input/arcface/tensorflow2/arcface_30epochs/1/04_model_arcface_v0.3_30.h5\")\\nbackbone_model.trainable = False\\nbackbone_model.summary()'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''backbone_model = tf.keras.models.load_model(\"/kaggle/input/arcface/tensorflow2/arcface_30epochs/1/04_model_arcface_v0.3_30.h5\")\n",
    "backbone_model.trainable = False\n",
    "backbone_model.summary()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7481923f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:01:34.482327Z",
     "iopub.status.busy": "2025-07-28T10:01:34.481849Z",
     "iopub.status.idle": "2025-07-28T10:01:34.486820Z",
     "shell.execute_reply": "2025-07-28T10:01:34.486064Z"
    },
    "papermill": {
     "duration": 0.033015,
     "end_time": "2025-07-28T10:01:34.488423",
     "exception": false,
     "start_time": "2025-07-28T10:01:34.455408",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'inputs_1 = tf.keras.Input(shape=INPUT_SHAPE, dtype=tf.float32)\\ninputs_2 = tf.keras.Input(shape=INPUT_SHAPE, dtype=tf.float32)\\nx_1 = backbone_model(inputs_1)\\nx_2 = backbone_model(inputs_2)\\nx = tf.keras.layers.concatenate([x_1, x_2])\\nx = tf.keras.layers.Dense(128, activation=\"gelu\") (x)\\noutputs = tf.keras.layers.Dense(1, activation=\"sigmoid\") (x)\\nmodel = tf.keras.models.Model(inputs=[inputs_1, inputs_2], outputs=outputs)\\nmodel.summary()'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''inputs_1 = tf.keras.Input(shape=INPUT_SHAPE, dtype=tf.float32)\n",
    "inputs_2 = tf.keras.Input(shape=INPUT_SHAPE, dtype=tf.float32)\n",
    "x_1 = backbone_model(inputs_1)\n",
    "x_2 = backbone_model(inputs_2)\n",
    "x = tf.keras.layers.concatenate([x_1, x_2])\n",
    "x = tf.keras.layers.Dense(128, activation=\"gelu\") (x)\n",
    "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\") (x)\n",
    "model = tf.keras.models.Model(inputs=[inputs_1, inputs_2], outputs=outputs)\n",
    "model.summary()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bc637a63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:01:34.541390Z",
     "iopub.status.busy": "2025-07-28T10:01:34.540629Z",
     "iopub.status.idle": "2025-07-28T10:01:34.544427Z",
     "shell.execute_reply": "2025-07-28T10:01:34.543637Z"
    },
    "papermill": {
     "duration": 0.031964,
     "end_time": "2025-07-28T10:01:34.546051",
     "exception": false,
     "start_time": "2025-07-28T10:01:34.514087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model = tf.keras.models.load_model(\"/kaggle/input/similarity_model/tensorflow2/similarity_model_3_epochs/1/07_similarity_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bbcb1e4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:01:34.599096Z",
     "iopub.status.busy": "2025-07-28T10:01:34.598814Z",
     "iopub.status.idle": "2025-07-28T10:01:34.603887Z",
     "shell.execute_reply": "2025-07-28T10:01:34.603073Z"
    },
    "papermill": {
     "duration": 0.03344,
     "end_time": "2025-07-28T10:01:34.605512",
     "exception": false,
     "start_time": "2025-07-28T10:01:34.572072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\\n              loss=\"binary_crossentropy\",\\n              metrics=[\"accuracy\"])'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3f2b08ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:01:34.658956Z",
     "iopub.status.busy": "2025-07-28T10:01:34.658668Z",
     "iopub.status.idle": "2025-07-28T10:01:34.663783Z",
     "shell.execute_reply": "2025-07-28T10:01:34.663075Z"
    },
    "papermill": {
     "duration": 0.033622,
     "end_time": "2025-07-28T10:01:34.665359",
     "exception": false,
     "start_time": "2025-07-28T10:01:34.631737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"checkpoint_path = 'cp-{epoch:04d}.h5'\\ncallbacks = [\\n    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\\n                                       save_weights_only=False,\\n                                       verbose=1)]\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''checkpoint_path = 'cp-{epoch:04d}.h5'\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                       save_weights_only=False,\n",
    "                                       verbose=1)]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6666a1b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:01:34.718567Z",
     "iopub.status.busy": "2025-07-28T10:01:34.718311Z",
     "iopub.status.idle": "2025-07-28T10:01:34.723288Z",
     "shell.execute_reply": "2025-07-28T10:01:34.722544Z"
    },
    "papermill": {
     "duration": 0.033514,
     "end_time": "2025-07-28T10:01:34.724829",
     "exception": false,
     "start_time": "2025-07-28T10:01:34.691315",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model.fit(train_data_generator,\\n          validation_data=test_data_generator,\\n          epochs=3,\\n          verbose=1,\\n          callbacks=callbacks)'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''model.fit(train_data_generator,\n",
    "          validation_data=test_data_generator,\n",
    "          epochs=3,\n",
    "          verbose=1,\n",
    "          callbacks=callbacks)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "29a100b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:01:34.778651Z",
     "iopub.status.busy": "2025-07-28T10:01:34.778320Z",
     "iopub.status.idle": "2025-07-28T10:01:34.783455Z",
     "shell.execute_reply": "2025-07-28T10:01:34.782712Z"
    },
    "papermill": {
     "duration": 0.034069,
     "end_time": "2025-07-28T10:01:34.785033",
     "exception": false,
     "start_time": "2025-07-28T10:01:34.750964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model.save(\"07_similarity_model.h5\")'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''model.save(\"07_similarity_model.h5\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73843e0",
   "metadata": {
    "papermill": {
     "duration": 0.026054,
     "end_time": "2025-07-28T10:01:34.837516",
     "exception": false,
     "start_time": "2025-07-28T10:01:34.811462",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# FINAL PREDICT ON DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a17e6f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T08:47:44.347606Z",
     "iopub.status.busy": "2024-03-07T08:47:44.346997Z",
     "iopub.status.idle": "2024-03-07T08:47:44.358911Z",
     "shell.execute_reply": "2024-03-07T08:47:44.358074Z",
     "shell.execute_reply.started": "2024-03-07T08:47:44.347575Z"
    },
    "papermill": {
     "duration": 0.025865,
     "end_time": "2025-07-28T10:01:34.889820",
     "exception": false,
     "start_time": "2025-07-28T10:01:34.863955",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8bc001b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:01:34.944770Z",
     "iopub.status.busy": "2025-07-28T10:01:34.944355Z",
     "iopub.status.idle": "2025-07-28T10:01:34.951497Z",
     "shell.execute_reply": "2025-07-28T10:01:34.950544Z"
    },
    "papermill": {
     "duration": 0.036864,
     "end_time": "2025-07-28T10:01:34.953267",
     "exception": false,
     "start_time": "2025-07-28T10:01:34.916403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom numpy import random\\nimport os \\nimport pandas as pd\\n\\nimage_paths = []\\n\\n# Iterar sobre las subcarpetas numeradas\\nfor folder_num in range(1, MAX_SUBJECTS):\\n    folder_path = os.path.join(PATH_SYNC, str(folder_num))\\n    if os.path.exists(folder_path):\\n        images = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith('.png')]\\n        image_paths.extend(images)\\n\\nfrom numpy import random\\ndef get_pairs(images, image_paths):\\n    if len(images) < 4:\\n        remplacement = True\\n    else:\\n        remplacement = False\\n    positive_pairs = random.choice(images, 4, remplacement)\\n    #user_id = os.path.basename(os.path.normpath(os.path.dirname(positive_pairs[0])))\\n    negative_pairs = random.choice([img_path for img_path in image_paths if img_path not in images], 3, False)\\n    pairs_pos = [(positive_pairs[0], positive_pairs[1:], 1)]\\n    pairs_neg = [(positive_pairs[0], negative_pairs, 0)]\\n    return pairs_pos, pairs_neg\\n\\npairs_list = []\\n\\nfor folder_num in range(1, MAX_SUBJECTS):\\n    folder_path = os.path.join(PATH_SYNC, str(folder_num))\\n    if os.path.exists(folder_path):\\n        images = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith('.png')]\\n        pairs_pos, pairs_neg = get_pairs(images, image_paths)\\n        pairs_list.extend(pairs_pos + pairs_neg)\\n\\ndf = pd.DataFrame([(item[0], img, item[2]) for item in pairs_list for img in item[1]], columns=['user_path', 'pair_path', 'positive_pair'])\\ndf.to_csv('faces-webface_pairs.csv', index=False)\\n\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from numpy import random\n",
    "import os \n",
    "import pandas as pd\n",
    "\n",
    "image_paths = []\n",
    "\n",
    "# Iterar sobre las subcarpetas numeradas\n",
    "for folder_num in range(1, MAX_SUBJECTS):\n",
    "    folder_path = os.path.join(PATH_SYNC, str(folder_num))\n",
    "    if os.path.exists(folder_path):\n",
    "        images = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith('.png')]\n",
    "        image_paths.extend(images)\n",
    "\n",
    "from numpy import random\n",
    "def get_pairs(images, image_paths):\n",
    "    if len(images) < 4:\n",
    "        remplacement = True\n",
    "    else:\n",
    "        remplacement = False\n",
    "    positive_pairs = random.choice(images, 4, remplacement)\n",
    "    #user_id = os.path.basename(os.path.normpath(os.path.dirname(positive_pairs[0])))\n",
    "    negative_pairs = random.choice([img_path for img_path in image_paths if img_path not in images], 3, False)\n",
    "    pairs_pos = [(positive_pairs[0], positive_pairs[1:], 1)]\n",
    "    pairs_neg = [(positive_pairs[0], negative_pairs, 0)]\n",
    "    return pairs_pos, pairs_neg\n",
    "\n",
    "pairs_list = []\n",
    "\n",
    "for folder_num in range(1, MAX_SUBJECTS):\n",
    "    folder_path = os.path.join(PATH_SYNC, str(folder_num))\n",
    "    if os.path.exists(folder_path):\n",
    "        images = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith('.png')]\n",
    "        pairs_pos, pairs_neg = get_pairs(images, image_paths)\n",
    "        pairs_list.extend(pairs_pos + pairs_neg)\n",
    "\n",
    "df = pd.DataFrame([(item[0], img, item[2]) for item in pairs_list for img in item[1]], columns=['user_path', 'pair_path', 'positive_pair'])\n",
    "df.to_csv('faces-webface_pairs.csv', index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a695f0c4",
   "metadata": {
    "papermill": {
     "duration": 0.026557,
     "end_time": "2025-07-28T10:01:35.007630",
     "exception": false,
     "start_time": "2025-07-28T10:01:34.981073",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "835129f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:01:35.062061Z",
     "iopub.status.busy": "2025-07-28T10:01:35.061758Z",
     "iopub.status.idle": "2025-07-28T10:01:35.065391Z",
     "shell.execute_reply": "2025-07-28T10:01:35.064745Z"
    },
    "papermill": {
     "duration": 0.032737,
     "end_time": "2025-07-28T10:01:35.066957",
     "exception": false,
     "start_time": "2025-07-28T10:01:35.034220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "618b359b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:01:35.121856Z",
     "iopub.status.busy": "2025-07-28T10:01:35.121561Z",
     "iopub.status.idle": "2025-07-28T10:01:35.594721Z",
     "shell.execute_reply": "2025-07-28T10:01:35.593947Z"
    },
    "papermill": {
     "duration": 0.502396,
     "end_time": "2025-07-28T10:01:35.596888",
     "exception": false,
     "start_time": "2025-07-28T10:01:35.094492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/faces-webface-pairs/faces-webface_pairs.csv\")\n",
    "results = np.array(df.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "36b7ced2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:01:35.651934Z",
     "iopub.status.busy": "2025-07-28T10:01:35.651610Z",
     "iopub.status.idle": "2025-07-28T10:01:35.658695Z",
     "shell.execute_reply": "2025-07-28T10:01:35.657971Z"
    },
    "papermill": {
     "duration": 0.035971,
     "end_time": "2025-07-28T10:01:35.660178",
     "exception": false,
     "start_time": "2025-07-28T10:01:35.624207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class IdentificationDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, \n",
    "                 comparison: np.ndarray,\n",
    "                 batch_size: Optional[int] = 8):\n",
    "        self.comparison = comparison\n",
    "        self.batch_size = batch_size\n",
    "        self.indexes = np.arange(self.comparison.shape[0])\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.indexes) / self.batch_size))\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        comparison = self.comparison[self.indexes[idx * self.batch_size : (idx + 1) * self.batch_size]]\n",
    "        X_1 = []\n",
    "        X_2 = []\n",
    "        y = np.zeros(len(comparison), dtype=np.float32)\n",
    "        for i, [path_user_1, path_user_2, pair_positive] in enumerate(comparison):\n",
    "            X_1 += [np.asarray(Image.open(path_user_1), dtype=np.float32)]\n",
    "            X_2 += [np.asarray(Image.open(path_user_2), dtype=np.float32)]\n",
    "            y[i] = pair_positive\n",
    "        X_1 = np.stack(X_1)\n",
    "        X_2 = np.stack(X_2)\n",
    "        \n",
    "        return [X_1 / 255., X_2 / 255.], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a2d312b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:01:35.714058Z",
     "iopub.status.busy": "2025-07-28T10:01:35.713780Z",
     "iopub.status.idle": "2025-07-28T10:01:35.717662Z",
     "shell.execute_reply": "2025-07-28T10:01:35.716902Z"
    },
    "papermill": {
     "duration": 0.032999,
     "end_time": "2025-07-28T10:01:35.719269",
     "exception": false,
     "start_time": "2025-07-28T10:01:35.686270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_generator = IdentificationDataGenerator(comparison=results,\n",
    "                                             batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1b65419a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:01:35.772253Z",
     "iopub.status.busy": "2025-07-28T10:01:35.771987Z",
     "iopub.status.idle": "2025-07-28T10:08:18.959177Z",
     "shell.execute_reply": "2025-07-28T10:08:18.958185Z"
    },
    "papermill": {
     "duration": 403.216085,
     "end_time": "2025-07-28T10:08:18.961354",
     "exception": false,
     "start_time": "2025-07-28T10:01:35.745269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_labels = []\n",
    "for idx in range(len(data_generator)):\n",
    "    _, labels = data_generator[idx]\n",
    "    all_labels.extend(labels.tolist())\n",
    "all_labels = np.array(all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bf0d3f",
   "metadata": {
    "papermill": {
     "duration": 0.026158,
     "end_time": "2025-07-28T10:08:19.014925",
     "exception": false,
     "start_time": "2025-07-28T10:08:18.988767",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Predict Similarity model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "62a8d43e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:08:19.068649Z",
     "iopub.status.busy": "2025-07-28T10:08:19.068071Z",
     "iopub.status.idle": "2025-07-28T10:08:21.455862Z",
     "shell.execute_reply": "2025-07-28T10:08:21.455111Z"
    },
    "papermill": {
     "duration": 2.416991,
     "end_time": "2025-07-28T10:08:21.457922",
     "exception": false,
     "start_time": "2025-07-28T10:08:19.040931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "similarity_model = tf.keras.models.load_model(\"/kaggle/input/similarity_model/tensorflow2/similarity_model_3_epochs/1/07_similarity_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "57b47d2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:08:21.512960Z",
     "iopub.status.busy": "2025-07-28T10:08:21.512637Z",
     "iopub.status.idle": "2025-07-28T10:12:32.653178Z",
     "shell.execute_reply": "2025-07-28T10:12:32.652349Z"
    },
    "papermill": {
     "duration": 251.170087,
     "end_time": "2025-07-28T10:12:32.655159",
     "exception": false,
     "start_time": "2025-07-28T10:08:21.485072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1983/1983 [==============================] - 250s 124ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = similarity_model.predict(data_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "860be85f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:12:32.882054Z",
     "iopub.status.busy": "2025-07-28T10:12:32.881333Z",
     "iopub.status.idle": "2025-07-28T10:12:32.885679Z",
     "shell.execute_reply": "2025-07-28T10:12:32.884930Z"
    },
    "papermill": {
     "duration": 0.118839,
     "end_time": "2025-07-28T10:12:32.887275",
     "exception": false,
     "start_time": "2025-07-28T10:12:32.768436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions[predictions>=0.5]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8adb859f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:12:33.153777Z",
     "iopub.status.busy": "2025-07-28T10:12:33.153404Z",
     "iopub.status.idle": "2025-07-28T10:12:33.157771Z",
     "shell.execute_reply": "2025-07-28T10:12:33.157067Z"
    },
    "papermill": {
     "duration": 0.156899,
     "end_time": "2025-07-28T10:12:33.159250",
     "exception": false,
     "start_time": "2025-07-28T10:12:33.002351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions[predictions<0.5]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c0151c2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:12:33.384020Z",
     "iopub.status.busy": "2025-07-28T10:12:33.383684Z",
     "iopub.status.idle": "2025-07-28T10:12:33.393380Z",
     "shell.execute_reply": "2025-07-28T10:12:33.392706Z"
    },
    "papermill": {
     "duration": 0.124454,
     "end_time": "2025-07-28T10:12:33.394865",
     "exception": false,
     "start_time": "2025-07-28T10:12:33.270411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6290953236842936"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(all_labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bd1eda",
   "metadata": {
    "papermill": {
     "duration": 0.11082,
     "end_time": "2025-07-28T10:12:33.617194",
     "exception": false,
     "start_time": "2025-07-28T10:12:33.506374",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Predict over embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dee25bea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:12:33.851722Z",
     "iopub.status.busy": "2025-07-28T10:12:33.851338Z",
     "iopub.status.idle": "2025-07-28T10:12:35.288254Z",
     "shell.execute_reply": "2025-07-28T10:12:35.287313Z"
    },
    "papermill": {
     "duration": 1.559361,
     "end_time": "2025-07-28T10:12:35.290274",
     "exception": false,
     "start_time": "2025-07-28T10:12:33.730913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "arcface_model = tf.keras.models.load_model(\"/kaggle/input/arcface/tensorflow2/arcface_30epochs/1/04_model_arcface_v0.3_30.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c0a5674d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:12:35.515026Z",
     "iopub.status.busy": "2025-07-28T10:12:35.514687Z",
     "iopub.status.idle": "2025-07-28T10:12:35.519961Z",
     "shell.execute_reply": "2025-07-28T10:12:35.519180Z"
    },
    "papermill": {
     "duration": 0.119061,
     "end_time": "2025-07-28T10:12:35.521442",
     "exception": false,
     "start_time": "2025-07-28T10:12:35.402381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PairwiseLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, anchor, control):\n",
    "        distance = tf.expand_dims(tf.keras.losses.cosine_similarity(anchor, control) * -1., axis=1)\n",
    "        return tf.divide(tf.subtract(distance, tf.reduce_min(distance)),\n",
    "                         tf.subtract(tf.reduce_max(distance), tf.reduce_min(distance)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "23c4141b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:12:35.784253Z",
     "iopub.status.busy": "2025-07-28T10:12:35.783540Z",
     "iopub.status.idle": "2025-07-28T10:12:37.116612Z",
     "shell.execute_reply": "2025-07-28T10:12:37.115016Z"
    },
    "papermill": {
     "duration": 1.486783,
     "end_time": "2025-07-28T10:12:37.118403",
     "exception": false,
     "start_time": "2025-07-28T10:12:35.631620",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 112, 112, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 112, 112, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " model (Functional)          (None, 512)                  1095104   ['input_1[0][0]',             \n",
      "                                                                     'input_2[0][0]']             \n",
      "                                                                                                  \n",
      " pairwise_layer (PairwiseLa  (None, 1)                    0         ['model[0][0]',               \n",
      " yer)                                                                'model[1][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1095104 (4.18 MB)\n",
      "Trainable params: 1075520 (4.10 MB)\n",
      "Non-trainable params: 19584 (76.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = tf.keras.Input(shape=INPUT_SHAPE, dtype=tf.float32)\n",
    "inputs_2 = tf.keras.Input(shape=INPUT_SHAPE, dtype=tf.float32)\n",
    "x_1 = arcface_model(inputs_1)\n",
    "x_2 = arcface_model(inputs_2)\n",
    "outputs = PairwiseLayer() (x_1, x_2)\n",
    "model = tf.keras.models.Model(inputs=[inputs_1, inputs_2], outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ea4d4dde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:12:37.345409Z",
     "iopub.status.busy": "2025-07-28T10:12:37.345051Z",
     "iopub.status.idle": "2025-07-28T10:16:32.558804Z",
     "shell.execute_reply": "2025-07-28T10:16:32.557862Z"
    },
    "papermill": {
     "duration": 235.330063,
     "end_time": "2025-07-28T10:16:32.561063",
     "exception": false,
     "start_time": "2025-07-28T10:12:37.231000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1983/1983 [==============================] - 234s 117ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(data_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "14c4dccd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:16:32.964644Z",
     "iopub.status.busy": "2025-07-28T10:16:32.963965Z",
     "iopub.status.idle": "2025-07-28T10:16:32.968054Z",
     "shell.execute_reply": "2025-07-28T10:16:32.967345Z"
    },
    "papermill": {
     "duration": 0.20641,
     "end_time": "2025-07-28T10:16:32.969622",
     "exception": false,
     "start_time": "2025-07-28T10:16:32.763212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions_copy = predictions.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f9247ddd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:16:33.366346Z",
     "iopub.status.busy": "2025-07-28T10:16:33.366016Z",
     "iopub.status.idle": "2025-07-28T10:16:33.370546Z",
     "shell.execute_reply": "2025-07-28T10:16:33.369723Z"
    },
    "papermill": {
     "duration": 0.205791,
     "end_time": "2025-07-28T10:16:33.372099",
     "exception": false,
     "start_time": "2025-07-28T10:16:33.166308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions_copy[predictions_copy>=0.5]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "41c29448",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:16:33.818103Z",
     "iopub.status.busy": "2025-07-28T10:16:33.817736Z",
     "iopub.status.idle": "2025-07-28T10:16:33.822426Z",
     "shell.execute_reply": "2025-07-28T10:16:33.821676Z"
    },
    "papermill": {
     "duration": 0.2531,
     "end_time": "2025-07-28T10:16:33.824079",
     "exception": false,
     "start_time": "2025-07-28T10:16:33.570979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions_copy[predictions_copy<0.5]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0e0746c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:16:34.248991Z",
     "iopub.status.busy": "2025-07-28T10:16:34.248667Z",
     "iopub.status.idle": "2025-07-28T10:16:34.256939Z",
     "shell.execute_reply": "2025-07-28T10:16:34.256164Z"
    },
    "papermill": {
     "duration": 0.20914,
     "end_time": "2025-07-28T10:16:34.258527",
     "exception": false,
     "start_time": "2025-07-28T10:16:34.049387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9014284362879577"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(all_labels, predictions_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0de22137",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:16:34.663224Z",
     "iopub.status.busy": "2025-07-28T10:16:34.662406Z",
     "iopub.status.idle": "2025-07-28T10:16:34.666707Z",
     "shell.execute_reply": "2025-07-28T10:16:34.665895Z"
    },
    "papermill": {
     "duration": 0.209445,
     "end_time": "2025-07-28T10:16:34.668223",
     "exception": false,
     "start_time": "2025-07-28T10:16:34.458778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions_copy_2 = predictions.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "78978fab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:16:35.070260Z",
     "iopub.status.busy": "2025-07-28T10:16:35.069925Z",
     "iopub.status.idle": "2025-07-28T10:16:35.074640Z",
     "shell.execute_reply": "2025-07-28T10:16:35.073726Z"
    },
    "papermill": {
     "duration": 0.208412,
     "end_time": "2025-07-28T10:16:35.076273",
     "exception": false,
     "start_time": "2025-07-28T10:16:34.867861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions_copy_2[predictions_copy_2>=0.42]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f74b0369",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:16:35.514475Z",
     "iopub.status.busy": "2025-07-28T10:16:35.514119Z",
     "iopub.status.idle": "2025-07-28T10:16:35.518366Z",
     "shell.execute_reply": "2025-07-28T10:16:35.517635Z"
    },
    "papermill": {
     "duration": 0.207391,
     "end_time": "2025-07-28T10:16:35.519876",
     "exception": false,
     "start_time": "2025-07-28T10:16:35.312485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions_copy_2[predictions_copy_2<0.42]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "927f494b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T10:16:35.925263Z",
     "iopub.status.busy": "2025-07-28T10:16:35.924619Z",
     "iopub.status.idle": "2025-07-28T10:16:35.932320Z",
     "shell.execute_reply": "2025-07-28T10:16:35.931490Z"
    },
    "papermill": {
     "duration": 0.213237,
     "end_time": "2025-07-28T10:16:35.933939",
     "exception": false,
     "start_time": "2025-07-28T10:16:35.720702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9124491533440545"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(all_labels, predictions_copy_2)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4340552,
     "sourceId": 7456892,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4499996,
     "sourceId": 7707383,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4557803,
     "sourceId": 7787019,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 12162,
     "modelInstanceId": 9218,
     "sourceId": 11435,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 12162,
     "modelInstanceId": 9273,
     "sourceId": 11499,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 12162,
     "modelInstanceId": 9873,
     "sourceId": 12169,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 16282,
     "modelInstanceId": 11433,
     "sourceId": 13812,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1100.279005,
   "end_time": "2025-07-28T10:16:39.401279",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-28T09:58:19.122274",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
